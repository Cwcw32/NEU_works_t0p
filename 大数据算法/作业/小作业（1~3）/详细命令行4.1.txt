 * Canonical Livepatch is available for installation.
   - Reduce system reboots and improve kernel security. Activate at:
     https://ubuntu.com/livepatch

108 个可升级软件包。
29 个安全更新。

Your Hardware Enablement Stack (HWE) is supported until April 2023.
Last login: Thu Jun 10 03:09:37 2021 from 127.0.0.1
jmq@Master:~$ start-dfs.sh
Starting namenodes on [Master]
Master: ssh: connect to host master port 22: No route to host
Starting datanodes
Master: ssh: connect to host master port 22: No route to host
Starting secondary namenodes [Master]
Master: ssh: connect to host master port 22: No route to host
jmq@Master:~$ ping 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.024 ms
64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.028 ms
^C
--- 127.0.0.1 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1025ms
rtt min/avg/max/mdev = 0.024/0.026/0.028/0.002 ms
jmq@Master:~$ ssh Slave1
Welcome to Ubuntu 18.04.5 LTS (GNU/Linux 5.4.0-42-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage


 * Canonical Livepatch is available for installation.
   - Reduce system reboots and improve kernel security. Activate at:
     https://ubuntu.com/livepatch

275 个可升级软件包。
210 个安全更新。

New release '20.04.2 LTS' available.
Run 'do-release-upgrade' to upgrade to it.

Your Hardware Enablement Stack (HWE) is supported until April 2023.
Last login: Sat May 29 00:28:31 2021 from 127.0.0.1
j@Slave1:~$ exot

Command 'exot' not found, did you mean:

  command 'exo' from snap exoscale-cli (v1.22.2)
  command 'emot' from deb ruby-emot

See 'snap info <snapname>' for additional versions.

j@Slave1:~$ exit
注销
Connection to slave1 closed.
jmq@Master:~$ start-dfs.sh
Starting namenodes on [Master]
Master: ssh: connect to host master port 22: No route to host
Starting datanodes
Slave1: datanode is running as process 2294.  Stop it first.
Slave2: datanode is running as process 2186.  Stop it first.
Master: ssh: connect to host master port 22: No route to host
Starting secondary namenodes [Master]
Master: ssh: connect to host master port 22: No route to host
jmq@Master:~$ stop-dfs.sh
Stopping namenodes on [Master]
Master: ssh: connect to host master port 22: No route to host
Stopping datanodes
Master: ssh: connect to host master port 22: No route to host
Stopping secondary namenodes [Master]
Master: ssh: connect to host master port 22: No route to host
jmq@Master:~$ ifconfig

Command 'ifconfig' not found, but can be installed with:

sudo apt install net-tools

jmq@Master:~$ sudo apt install net-tools
[sudo] j 的密码： 
E: dpkg 被中断，您必须手工运行 ‘sudo dpkg --configure -a’ 解决此问题。
jmq@Master:~$ sudo apt install net-tools
E: dpkg 被中断，您必须手工运行 ‘sudo dpkg --configure -a’ 解决此问题。
jmq@Master:~$ sudo rm /var/lib/dpkg/updates/*
jmq@Master:~$ sudo apt-get update
命中:1 http://mirrors.aliyun.com/ubuntu bionic InRelease
获取:2 http://mirrors.aliyun.com/ubuntu bionic-updates InRelease [88.7 kB]    
获取:3 http://mirrors.aliyun.com/ubuntu bionic-backports InRelease [74.6 kB]  
获取:4 http://mirrors.aliyun.com/ubuntu bionic-security InRelease [88.7 kB]
获取:5 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [294 kB]
获取:6 http://mirrors.aliyun.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [290 kB]
获取:7 http://mirrors.aliyun.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2,468 B]
获取:8 http://mirrors.aliyun.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [9,292 B]
获取:9 http://mirrors.aliyun.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [48.5 kB]
获取:10 http://mirrors.aliyun.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [60.3 kB]
获取:11 http://mirrors.aliyun.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2,464 B]
已下载 958 kB，耗时 1秒 (970 kB/s)                                           

正在读取软件包列表... 完成
jmq@Master:~$ 
jmq@Master:~$ sudo apt-get upgrade
正在读取软件包列表... 完成
正在分析软件包的依赖关系树       
正在读取状态信息... 完成       
正在计算更新... 完成
下列软件包的版本将保持不变：
  linux-generic-hwe-18.04 linux-headers-generic-hwe-18.04
  linux-image-generic-hwe-18.04 ubuntu-advantage-tools ubuntu-drivers-common
下列软件包将被升级：
  apt apt-utils base-files bind9-host dirmngr dnsutils friendly-recovery gdb
  gdbserver gir1.2-mutter-2 gnome-shell gnome-shell-common gnupg gnupg-l10n
  gnupg-utils gpg gpg-agent gpg-wks-client gpg-wks-server gpgconf gpgsm gpgv
  grub-common grub-pc grub-pc-bin grub2-common initramfs-tools
  initramfs-tools-bin initramfs-tools-core iproute2 libappindicator3-1
  libapt-inst2.0 libapt-pkg5.0 libaudit-common libaudit1 libbind9-160
  libc-bin libc6 libc6-dbg libcryptsetup12 libdns1100 libevdev2 libinput-bin
  libinput10 libirs160 libisc169 libisccc160 libisccfg160 liblwres160
  libmutter-2-0 libnetplan0 libnss-myhostname libnss-systemd libpam-modules
  libpam-modules-bin libpam-runtime libpam-systemd libpam0g libpcap0.8
  libsane-common libsane1 libseccomp2 libsystemd0 libudev1 libwhoopsie0
  linux-firmware locales lshw multiarch-support mutter mutter-common
  netplan.io nplan python-apt-common python3-apt python3-distupgrade
  python3-httplib2 sane-utils sbsigntool snapd squashfs-tools systemd
  systemd-sysv thunderbird thunderbird-gnome-support thunderbird-locale-en
  thunderbird-locale-en-us thunderbird-locale-zh-cn
  thunderbird-locale-zh-hans ubuntu-desktop ubuntu-keyring ubuntu-minimal
  ubuntu-release-upgrader-core ubuntu-release-upgrader-gtk ubuntu-standard
  udev update-notifier update-notifier-common whoopsie
升级了 99 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 5 个软件包未被升级。
需要下载 154 MB/187 MB 的归档。
解压缩后会消耗 35.5 MB 的额外空间。
您希望继续执行吗？ [Y/n] y
获取:1 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 snapd amd64 2.49.2+18.04 [22.5 MB]
获取:2 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 libpam0g amd64 1.1.8-3.6ubuntu2.18.04.3 [55.0 kB]                                  
获取:3 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 libpam-modules-bin amd64 1.1.8-3.6ubuntu2.18.04.3 [40.3 kB]                        
获取:4 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 libpam-modules amd64 1.1.8-3.6ubuntu2.18.04.3 [252 kB]                             
获取:5 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 libpam-runtime all 1.1.8-3.6ubuntu2.18.04.3 [37.1 kB]                              
获取:6 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 squashfs-tools amd64 1:4.3-6ubuntu0.18.04.2 [111 kB]                               
获取:7 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 python-apt-common all 1.6.5ubuntu0.6 [17.0 kB]                                     
获取:8 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 python3-apt amd64 1.6.5ubuntu0.6 [149 kB]                                          
获取:9 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 update-notifier amd64 3.192.1.11 [55.8 kB]                                         
获取:10 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 update-notifier-common all 3.192.1.11 [133 kB]                                    
获取:11 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 gdb amd64 8.1.1-0ubuntu1 [2,937 kB]                                               
获取:12 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 gdbserver amd64 8.1.1-0ubuntu1 [282 kB]                                           
获取:13 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 linux-firmware all 1.173.20 [74.8 MB]                                             
获取:14 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 sbsigntool amd64 0.9.2-2ubuntu1~18.04.1 [62.6 kB]                                 
获取:15 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 thunderbird-locale-zh-hans amd64 1:78.8.1+build1-0ubuntu0.18.04.1 [627 kB]        
获取:16 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 thunderbird-locale-en amd64 1:78.8.1+build1-0ubuntu0.18.04.1 [898 kB]             
获取:17 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 thunderbird amd64 1:78.8.1+build1-0ubuntu0.18.04.1 [50.8 MB]                      
获取:18 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 thunderbird-gnome-support amd64 1:78.8.1+build1-0ubuntu0.18.04.1 [8,640 B]        
获取:19 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 thunderbird-locale-en-us all 1:78.8.1+build1-0ubuntu0.18.04.1 [10.3 kB]           
获取:20 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 thunderbird-locale-zh-cn all 1:78.8.1+build1-0ubuntu0.18.04.1 [10.3 kB]           
获取:21 http://mirrors.aliyun.com/ubuntu bionic-updates/main amd64 ubuntu-desktop amd64 1.417.5 [3,592 B]                                            
已下载 154 MB，耗时 1分 20秒 (1,922 kB/s)                                                                                                            
正在从软件包中解出模板：100%
正在预设定软件包 ...
(正在读取数据库 ... 系统当前共安装有 134147 个文件和目录。)
正准备解包 .../libc6-dbg_2.27-3ubuntu1.4_amd64.deb  ...
正在将 libc6-dbg:amd64 (2.27-3ubuntu1.4) 解包到 (2.27-3ubuntu1.2) 上 ...
正准备解包 .../libc6_2.27-3ubuntu1.4_amd64.deb  ...
正在将 libc6:amd64 (2.27-3ubuntu1.4) 解包到 (2.27-3ubuntu1.2) 上 ...
正在设置 libc6:amd64 (2.27-3ubuntu1.4) ...
(正在读取数据库 ... 系统当前共安装有 134147 个文件和目录。)
正准备解包 .../base-files_10.1ubuntu2.10_amd64.deb  ...
Warning: Stopping motd-news.service, but it can still be activated by:
  motd-news.timer
正在将 base-files (10.1ubuntu2.10) 解包到 (10.1ubuntu2.9) 上 ...
正在设置 base-files (10.1ubuntu2.10) ...
正在安装新版本配置文件 /etc/update-motd.d/50-motd-news ...
motd-news.service is a disabled or a static unit, not starting it.
Removing obsolete conffile /etc/default/motd-news ...
(正在读取数据库 ... 系统当前共安装有 134146 个文件和目录。)
正准备解包 .../locales_2.27-3ubuntu1.4_all.deb  ...
正在将 locales (2.27-3ubuntu1.4) 解包到 (2.27-3ubuntu1.2) 上 ...
正准备解包 .../libc-bin_2.27-3ubuntu1.4_amd64.deb  ...
正在将 libc-bin (2.27-3ubuntu1.4) 解包到 (2.27-3ubuntu1.2) 上 ...
正在设置 libc-bin (2.27-3ubuntu1.4) ...
(正在读取数据库 ... 系统当前共安装有 134146 个文件和目录。)
正准备解包 .../libnss-systemd_237-3ubuntu10.47_amd64.deb  ...
正在将 libnss-systemd:amd64 (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正准备解包 .../libsystemd0_237-3ubuntu10.47_amd64.deb  ...
正在将 libsystemd0:amd64 (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正在设置 libsystemd0:amd64 (237-3ubuntu10.47) ...
(正在读取数据库 ... 系统当前共安装有 134146 个文件和目录。)
正准备解包 .../0-libnss-myhostname_237-3ubuntu10.47_amd64.deb  ...
正在将 libnss-myhostname:amd64 (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正准备解包 .../1-libpam-systemd_237-3ubuntu10.47_amd64.deb  ...
正在将 libpam-systemd:amd64 (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正准备解包 .../2-snapd_2.49.2+18.04_amd64.deb  ...
正在将 snapd (2.49.2+18.04) 解包到 (2.48.3+18.04) 上 ...
正准备解包 .../3-systemd_237-3ubuntu10.47_amd64.deb  ...
正在将 systemd (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正准备解包 .../4-udev_237-3ubuntu10.47_amd64.deb  ...
正在将 udev (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正准备解包 .../5-libudev1_237-3ubuntu10.47_amd64.deb  ...
正在将 libudev1:amd64 (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正在设置 libudev1:amd64 (237-3ubuntu10.47) ...
(正在读取数据库 ... 系统当前共安装有 134148 个文件和目录。)
正准备解包 .../libaudit-common_1%3a2.8.2-1ubuntu1.1_all.deb  ...
正在将 libaudit-common (1:2.8.2-1ubuntu1.1) 解包到 (1:2.8.2-1ubuntu1) 上 ...
正在设置 libaudit-common (1:2.8.2-1ubuntu1.1) ...
(正在读取数据库 ... 系统当前共安装有 134148 个文件和目录。)
正准备解包 .../libaudit1_1%3a2.8.2-1ubuntu1.1_amd64.deb  ...
正在将 libaudit1:amd64 (1:2.8.2-1ubuntu1.1) 解包到 (1:2.8.2-1ubuntu1) 上 ...
正在设置 libaudit1:amd64 (1:2.8.2-1ubuntu1.1) ...
(正在读取数据库 ... 系统当前共安装有 134148 个文件和目录。)
正准备解包 .../libpam0g_1.1.8-3.6ubuntu2.18.04.3_amd64.deb  ...
正在将 libpam0g:amd64 (1.1.8-3.6ubuntu2.18.04.3) 解包到 (1.1.8-3.6ubuntu2.18.04.1) 上 ...
正在设置 libpam0g:amd64 (1.1.8-3.6ubuntu2.18.04.3) ...
(正在读取数据库 ... 系统当前共安装有 134148 个文件和目录。)
正准备解包 .../libpam-modules-bin_1.1.8-3.6ubuntu2.18.04.3_amd64.deb  ...
正在将 libpam-modules-bin (1.1.8-3.6ubuntu2.18.04.3) 解包到 (1.1.8-3.6ubuntu2.18.04.1) 上 ...
正在设置 libpam-modules-bin (1.1.8-3.6ubuntu2.18.04.3) ...
(正在读取数据库 ... 系统当前共安装有 134150 个文件和目录。)
正准备解包 .../libpam-modules_1.1.8-3.6ubuntu2.18.04.3_amd64.deb  ...
正在将 libpam-modules:amd64 (1.1.8-3.6ubuntu2.18.04.3) 解包到 (1.1.8-3.6ubuntu2.18.04.1) 上 ...
正在设置 libpam-modules:amd64 (1.1.8-3.6ubuntu2.18.04.3) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../libpam-runtime_1.1.8-3.6ubuntu2.18.04.3_all.deb  ...
正在将 libpam-runtime (1.1.8-3.6ubuntu2.18.04.3) 解包到 (1.1.8-3.6ubuntu2.18.04.1) 上 ...
正在设置 libpam-runtime (1.1.8-3.6ubuntu2.18.04.3) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../0-grub-pc_2.02-2ubuntu8.23_amd64.deb  ...
正在将 grub-pc (2.02-2ubuntu8.23) 解包到 (2.02-2ubuntu8.17) 上 ...
正准备解包 .../1-grub2-common_2.02-2ubuntu8.23_amd64.deb  ...
正在将 grub2-common (2.02-2ubuntu8.23) 解包到 (2.02-2ubuntu8.17) 上 ...
正准备解包 .../2-grub-pc-bin_2.02-2ubuntu8.23_amd64.deb  ...
正在将 grub-pc-bin (2.02-2ubuntu8.23) 解包到 (2.02-2ubuntu8.17) 上 ...
正准备解包 .../3-grub-common_2.02-2ubuntu8.23_amd64.deb  ...
正在将 grub-common (2.02-2ubuntu8.23) 解包到 (2.02-2ubuntu8.17) 上 ...
正准备解包 .../4-friendly-recovery_0.2.38ubuntu1.2_all.deb  ...
正在将 friendly-recovery (0.2.38ubuntu1.2) 解包到 (0.2.38ubuntu1.1) 上 ...
正准备解包 .../5-initramfs-tools_0.130ubuntu3.12_all.deb  ...
正在将 initramfs-tools (0.130ubuntu3.12) 解包到 (0.130ubuntu3.9) 上 ...
正准备解包 .../6-initramfs-tools-core_0.130ubuntu3.12_all.deb  ...
正在将 initramfs-tools-core (0.130ubuntu3.12) 解包到 (0.130ubuntu3.9) 上 ...
正准备解包 .../7-initramfs-tools-bin_0.130ubuntu3.12_amd64.deb  ...
正在将 initramfs-tools-bin (0.130ubuntu3.12) 解包到 (0.130ubuntu3.9) 上 ...
正在设置 systemd (237-3ubuntu10.47) ...
正在安装新版本配置文件 /etc/dhcp/dhclient-enter-hooks.d/resolved ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../systemd-sysv_237-3ubuntu10.47_amd64.deb  ...
正在将 systemd-sysv (237-3ubuntu10.47) 解包到 (237-3ubuntu10.42) 上 ...
正准备解包 .../squashfs-tools_1%3a4.3-6ubuntu0.18.04.2_amd64.deb  ...
正在将 squashfs-tools (1:4.3-6ubuntu0.18.04.2) 解包到 (1:4.3-6ubuntu0.18.04.1) 上 ...
正准备解包 .../libcryptsetup12_2%3a2.0.2-1ubuntu1.2_amd64.deb  ...
正在将 libcryptsetup12:amd64 (2:2.0.2-1ubuntu1.2) 解包到 (2:2.0.2-1ubuntu1.1) 上 ...
正准备解包 .../libapt-pkg5.0_1.6.13_amd64.deb  ...
正在将 libapt-pkg5.0:amd64 (1.6.13) 解包到 (1.6.12ubuntu0.2) 上 ...
正在设置 libapt-pkg5.0:amd64 (1.6.13) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../libapt-inst2.0_1.6.13_amd64.deb  ...
正在将 libapt-inst2.0:amd64 (1.6.13) 解包到 (1.6.12ubuntu0.2) 上 ...
正准备解包 .../archives/apt_1.6.13_amd64.deb  ...
正在将 apt (1.6.13) 解包到 (1.6.12ubuntu0.2) 上 ...
正在设置 apt (1.6.13) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../00-apt-utils_1.6.13_amd64.deb  ...
正在将 apt-utils (1.6.13) 解包到 (1.6.12ubuntu0.2) 上 ...
正准备解包 .../01-gpg-wks-client_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpg-wks-client (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../02-dirmngr_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 dirmngr (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../03-gpg_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpg (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../04-gnupg-utils_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gnupg-utils (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../05-gnupg-l10n_2.2.4-1ubuntu1.4_all.deb  ...
正在将 gnupg-l10n (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../06-gpg-agent_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpg-agent (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../07-gpgsm_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpgsm (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../08-gpgconf_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpgconf (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../09-gnupg_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gnupg (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../10-gpg-wks-server_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpg-wks-server (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正准备解包 .../11-gpgv_2.2.4-1ubuntu1.4_amd64.deb  ...
正在将 gpgv (2.2.4-1ubuntu1.4) 解包到 (2.2.4-1ubuntu1.2) 上 ...
正在设置 gpgv (2.2.4-1ubuntu1.4) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../ubuntu-keyring_2018.09.18.1~18.04.2_all.deb  ...
正在将 ubuntu-keyring (2018.09.18.1~18.04.2) 解包到 (2018.09.18.1~18.04.0) 上 ...
正在设置 ubuntu-keyring (2018.09.18.1~18.04.2) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../libseccomp2_2.5.1-1ubuntu1~18.04.1_amd64.deb  ...
正在将 libseccomp2:amd64 (2.5.1-1ubuntu1~18.04.1) 解包到 (2.4.3-1ubuntu3.18.04.3) 上 ...
正在设置 libseccomp2:amd64 (2.5.1-1ubuntu1~18.04.1) ...
(正在读取数据库 ... 系统当前共安装有 134154 个文件和目录。)
正准备解包 .../00-libappindicator3-1_12.10.1+18.04.20200408.1-0ubuntu1_amd64.deb  ...
正在将 libappindicator3-1 (12.10.1+18.04.20200408.1-0ubuntu1) 解包到 (12.10.1+18.04.20180322.1-0ubuntu1) 上 ...
正准备解包 .../01-libsane1_1.0.27-1~experimental3ubuntu2.4_amd64.deb  ...
正在将 libsane1:amd64 (1.0.27-1~experimental3ubuntu2.4) 解包到 (1.0.27-1~experimental3ubuntu2.3) 上 ...
正准备解包 .../02-libsane-common_1.0.27-1~experimental3ubuntu2.4_all.deb  ...
正在将 libsane-common (1.0.27-1~experimental3ubuntu2.4) 解包到 (1.0.27-1~experimental3ubuntu2.3) 上 ...
正准备解包 .../03-sane-utils_1.0.27-1~experimental3ubuntu2.4_amd64.deb  ...
正在将 sane-utils (1.0.27-1~experimental3ubuntu2.4) 解包到 (1.0.27-1~experimental3ubuntu2.3) 上 ...
正准备解包 .../04-python-apt-common_1.6.5ubuntu0.6_all.deb  ...
正在将 python-apt-common (1.6.5ubuntu0.6) 解包到 (1.6.5ubuntu0.5) 上 ...
正准备解包 .../05-python3-apt_1.6.5ubuntu0.6_amd64.deb  ...
正在将 python3-apt (1.6.5ubuntu0.6) 解包到 (1.6.5ubuntu0.5) 上 ...
正准备解包 .../06-ubuntu-release-upgrader-gtk_1%3a18.04.44_all.deb  ...
正在将 ubuntu-release-upgrader-gtk (1:18.04.44) 解包到 (1:18.04.38) 上 ...
正准备解包 .../07-ubuntu-release-upgrader-core_1%3a18.04.44_all.deb  ...
正在将 ubuntu-release-upgrader-core (1:18.04.44) 解包到 (1:18.04.38) 上 ...
正准备解包 .../08-python3-distupgrade_1%3a18.04.44_all.deb  ...
正在将 python3-distupgrade (1:18.04.44) 解包到 (1:18.04.38) 上 ...
正准备解包 .../09-libevdev2_1.5.8+dfsg-1ubuntu0.1_amd64.deb  ...
正在将 libevdev2:amd64 (1.5.8+dfsg-1ubuntu0.1) 解包到 (1.5.8+dfsg-1) 上 ...
正准备解包 .../10-libinput-bin_1.10.4-1ubuntu0.18.04.2_amd64.deb  ...
正在将 libinput-bin (1.10.4-1ubuntu0.18.04.2) 解包到 (1.10.4-1ubuntu0.18.04.1) 上 ...
正准备解包 .../11-libinput10_1.10.4-1ubuntu0.18.04.2_amd64.deb  ...
正在将 libinput10:amd64 (1.10.4-1ubuntu0.18.04.2) 解包到 (1.10.4-1ubuntu0.18.04.1) 上 ...
正准备解包 .../12-mutter-common_3.28.4+git20200505-0ubuntu18.04.2_all.deb  ...
正在将 mutter-common (3.28.4+git20200505-0ubuntu18.04.2) 解包到 (3.28.4-0ubuntu18.04.2) 上 ...
正准备解包 .../13-gir1.2-mutter-2_3.28.4+git20200505-0ubuntu18.04.2_amd64.deb  ...
正在将 gir1.2-mutter-2:amd64 (3.28.4+git20200505-0ubuntu18.04.2) 解包到 (3.28.4-0ubuntu18.04.2) 上 ...
正准备解包 .../14-libmutter-2-0_3.28.4+git20200505-0ubuntu18.04.2_amd64.deb  ...
正在将 libmutter-2-0:amd64 (3.28.4+git20200505-0ubuntu18.04.2) 解包到 (3.28.4-0ubuntu18.04.2) 上 ...
正准备解包 .../15-gnome-shell_3.28.4-0ubuntu18.04.7_amd64.deb  ...
正在将 gnome-shell (3.28.4-0ubuntu18.04.7) 解包到 (3.28.4-0ubuntu18.04.3) 上 ...
正准备解包 .../16-gnome-shell-common_3.28.4-0ubuntu18.04.7_all.deb  ...
正在将 gnome-shell-common (3.28.4-0ubuntu18.04.7) 解包到 (3.28.4-0ubuntu18.04.3) 上 ...
正准备解包 .../17-mutter_3.28.4+git20200505-0ubuntu18.04.2_amd64.deb  ...
正在将 mutter (3.28.4+git20200505-0ubuntu18.04.2) 解包到 (3.28.4-0ubuntu18.04.2) 上 ...
正准备解包 .../18-update-notifier_3.192.1.11_amd64.deb  ...
正在将 update-notifier (3.192.1.11) 解包到 (3.192.1.7) 上 ...
正准备解包 .../19-update-notifier-common_3.192.1.11_all.deb  ...
正在将 update-notifier-common (3.192.1.11) 解包到 (3.192.1.7) 上 ...
正准备解包 .../20-whoopsie_0.2.62ubuntu0.6_amd64.deb  ...
正在将 whoopsie (0.2.62ubuntu0.6) 解包到 (0.2.62ubuntu0.5) 上 ...
正准备解包 .../21-libwhoopsie0_0.2.62ubuntu0.6_amd64.deb  ...
正在将 libwhoopsie0:amd64 (0.2.62ubuntu0.6) 解包到 (0.2.62ubuntu0.5) 上 ...
正准备解包 .../22-iproute2_4.15.0-2ubuntu1.3_amd64.deb  ...
正在将 iproute2 (4.15.0-2ubuntu1.3) 解包到 (4.15.0-2ubuntu1.2) 上 ...
正准备解包 .../23-libnetplan0_0.99-0ubuntu3~18.04.4_amd64.deb  ...
正在将 libnetplan0:amd64 (0.99-0ubuntu3~18.04.4) 解包到 (0.99-0ubuntu3~18.04.3) 上 ...
正准备解包 .../24-netplan.io_0.99-0ubuntu3~18.04.4_amd64.deb  ...
正在将 netplan.io (0.99-0ubuntu3~18.04.4) 解包到 (0.99-0ubuntu3~18.04.3) 上 ...
正准备解包 .../25-nplan_0.99-0ubuntu3~18.04.4_all.deb  ...
正在将 nplan (0.99-0ubuntu3~18.04.4) 解包到 (0.99-0ubuntu3~18.04.3) 上 ...
正准备解包 .../26-ubuntu-minimal_1.417.5_amd64.deb  ...
正在将 ubuntu-minimal (1.417.5) 解包到 (1.417.4) 上 ...
正准备解包 .../27-libirs160_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 libirs160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../28-bind9-host_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 bind9-host (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../29-dnsutils_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 dnsutils (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../30-libbind9-160_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 libbind9-160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../31-libisccfg160_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 libisccfg160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../32-libisccc160_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 libisccc160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../33-libdns1100_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 libdns1100:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../34-libisc169_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 libisc169:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../35-liblwres160_1%3a9.11.3+dfsg-1ubuntu1.15_amd64.deb  ...
正在将 liblwres160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) 解包到 (1:9.11.3+dfsg-1ubuntu1.12) 上 ...
正准备解包 .../36-libpcap0.8_1.8.1-6ubuntu1.18.04.2_amd64.deb  ...
正在将 libpcap0.8:amd64 (1.8.1-6ubuntu1.18.04.2) 解包到 (1.8.1-6ubuntu1.18.04.1) 上 ...
正准备解包 .../37-lshw_02.18-0.1ubuntu6.18.04.2_amd64.deb  ...
正在将 lshw (02.18-0.1ubuntu6.18.04.2) 解包到 (02.18-0.1ubuntu6.18.04.1) 上 ...
正准备解包 .../38-multiarch-support_2.27-3ubuntu1.4_amd64.deb  ...
正在将 multiarch-support (2.27-3ubuntu1.4) 解包到 (2.27-3ubuntu1.2) 上 ...
正准备解包 .../39-ubuntu-standard_1.417.5_amd64.deb  ...
正在将 ubuntu-standard (1.417.5) 解包到 (1.417.4) 上 ...
正准备解包 .../40-gdb_8.1.1-0ubuntu1_amd64.deb  ...
正在将 gdb (8.1.1-0ubuntu1) 解包到 (8.1-0ubuntu3.2) 上 ...
正准备解包 .../41-gdbserver_8.1.1-0ubuntu1_amd64.deb  ...
正在将 gdbserver (8.1.1-0ubuntu1) 解包到 (8.1-0ubuntu3.2) 上 ...
正准备解包 .../42-linux-firmware_1.173.20_all.deb  ...
正在将 linux-firmware (1.173.20) 解包到 (1.173.19) 上 ...
正准备解包 .../43-python3-httplib2_0.9.2+dfsg-1ubuntu0.3_all.deb  ...
正在将 python3-httplib2 (0.9.2+dfsg-1ubuntu0.3) 解包到 (0.9.2+dfsg-1ubuntu0.2) 上 ...
正准备解包 .../44-sbsigntool_0.9.2-2ubuntu1~18.04.1_amd64.deb  ...
正在将 sbsigntool (0.9.2-2ubuntu1~18.04.1) 解包到 (0.6-3.2ubuntu2) 上 ...
正准备解包 .../45-thunderbird-locale-zh-hans_1%3a78.8.1+build1-0ubuntu0.18.04.1_amd64.deb  ...
正在将 thunderbird-locale-zh-hans (1:78.8.1+build1-0ubuntu0.18.04.1) 解包到 (1:68.10.0+build1-0ubuntu0.18.04.1) 上 ...
正准备解包 .../46-thunderbird-locale-en_1%3a78.8.1+build1-0ubuntu0.18.04.1_amd64.deb  ...
正在将 thunderbird-locale-en (1:78.8.1+build1-0ubuntu0.18.04.1) 解包到 (1:68.10.0+build1-0ubuntu0.18.04.1) 上 ...
正准备解包 .../47-thunderbird_1%3a78.8.1+build1-0ubuntu0.18.04.1_amd64.deb  ...
正在将 thunderbird (1:78.8.1+build1-0ubuntu0.18.04.1) 解包到 (1:68.10.0+build1-0ubuntu0.18.04.1) 上 ...
正准备解包 .../48-thunderbird-gnome-support_1%3a78.8.1+build1-0ubuntu0.18.04.1_amd64.deb  ...
正在将 thunderbird-gnome-support (1:78.8.1+build1-0ubuntu0.18.04.1) 解包到 (1:68.10.0+build1-0ubuntu0.18.04.1) 上 ...
正准备解包 .../49-thunderbird-locale-en-us_1%3a78.8.1+build1-0ubuntu0.18.04.1_all.deb  ...
正在将 thunderbird-locale-en-us (1:78.8.1+build1-0ubuntu0.18.04.1) 解包到 (1:68.10.0+build1-0ubuntu0.18.04.1) 上 ...
正准备解包 .../50-thunderbird-locale-zh-cn_1%3a78.8.1+build1-0ubuntu0.18.04.1_all.deb  ...
正在将 thunderbird-locale-zh-cn (1:78.8.1+build1-0ubuntu0.18.04.1) 解包到 (1:68.10.0+build1-0ubuntu0.18.04.1) 上 ...
正准备解包 .../51-ubuntu-desktop_1.417.5_amd64.deb  ...
正在将 ubuntu-desktop (1.417.5) 解包到 (1.417.4) 上 ...
正在设置 python-apt-common (1.6.5ubuntu0.6) ...
正在设置 libisc169:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 libapt-inst2.0:amd64 (1.6.13) ...
正在设置 libnss-systemd:amd64 (237-3ubuntu10.47) ...
正在设置 libisccc160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 libc6-dbg:amd64 (2.27-3ubuntu1.4) ...
正在设置 python3-apt (1.6.5ubuntu0.6) ...
正在设置 libcryptsetup12:amd64 (2:2.0.2-1ubuntu1.2) ...
正在设置 update-notifier-common (3.192.1.11) ...
正在设置 libevdev2:amd64 (1.5.8+dfsg-1ubuntu0.1) ...
正在设置 libnss-myhostname:amd64 (237-3ubuntu10.47) ...
正在设置 apt-utils (1.6.13) ...
正在设置 multiarch-support (2.27-3ubuntu1.4) ...
正在设置 systemd-sysv (237-3ubuntu10.47) ...
正在设置 mutter-common (3.28.4+git20200505-0ubuntu18.04.2) ...
正在设置 gpgconf (2.2.4-1ubuntu1.4) ...
正在设置 gpg-agent (2.2.4-1ubuntu1.4) ...
正在设置 lshw (02.18-0.1ubuntu6.18.04.2) ...
正在设置 iproute2 (4.15.0-2ubuntu1.3) ...
正在设置 libinput-bin (1.10.4-1ubuntu0.18.04.2) ...
正在设置 thunderbird (1:78.8.1+build1-0ubuntu0.18.04.1) ...
正在设置 gnupg-l10n (2.2.4-1ubuntu1.4) ...
正在设置 libsane-common (1.0.27-1~experimental3ubuntu2.4) ...
正在设置 gnome-shell-common (3.28.4-0ubuntu18.04.7) ...
正在设置 squashfs-tools (1:4.3-6ubuntu0.18.04.2) ...
正在设置 udev (237-3ubuntu10.47) ...
update-initramfs: deferring update (trigger activated)
正在设置 grub-common (2.02-2ubuntu8.23) ...
正在安装新版本配置文件 /etc/grub.d/10_linux ...
update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults
正在设置 thunderbird-gnome-support (1:78.8.1+build1-0ubuntu0.18.04.1) ...
正在设置 gpgsm (2.2.4-1ubuntu1.4) ...
正在设置 python3-httplib2 (0.9.2+dfsg-1ubuntu0.3) ...
正在设置 sbsigntool (0.9.2-2ubuntu1~18.04.1) ...
正在设置 gnupg-utils (2.2.4-1ubuntu1.4) ...
正在设置 thunderbird-locale-zh-hans (1:78.8.1+build1-0ubuntu0.18.04.1) ...
正在设置 libsane1:amd64 (1.0.27-1~experimental3ubuntu2.4) ...
正在设置 gdbserver (8.1.1-0ubuntu1) ...
正在设置 initramfs-tools-bin (0.130ubuntu3.12) ...
正在设置 libnetplan0:amd64 (0.99-0ubuntu3~18.04.4) ...
正在设置 friendly-recovery (0.2.38ubuntu1.2) ...
Sourcing file `/etc/default/grub'
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-5.4.0-74-generic
Found linux image: /boot/vmlinuz-5.4.0-42-generic
Found initrd image: /boot/initrd.img-5.4.0-42-generic
Found memtest86+ image: /boot/memtest86+.elf
Found memtest86+ image: /boot/memtest86+.bin
done
正在设置 libappindicator3-1 (12.10.1+18.04.20200408.1-0ubuntu1) ...
正在设置 libdns1100:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 dirmngr (2.2.4-1ubuntu1.4) ...
正在设置 sane-utils (1.0.27-1~experimental3ubuntu2.4) ...
正在设置 gdb (8.1.1-0ubuntu1) ...
正在设置 locales (2.27-3ubuntu1.4) ...
Generating locales (this might take a while)...
  en_AG.UTF-8... done
  en_AU.UTF-8... done
  en_BW.UTF-8... done
  en_CA.UTF-8... done
  en_DK.UTF-8... done
  en_GB.UTF-8... done
  en_HK.UTF-8... done
  en_IE.UTF-8... done
  en_IL.UTF-8... done
  en_IN.UTF-8... done
  en_NG.UTF-8... done
  en_NZ.UTF-8... done
  en_PH.UTF-8... done
  en_SG.UTF-8... done
  en_US.UTF-8... done
  en_ZA.UTF-8... done
  en_ZM.UTF-8... done
  en_ZW.UTF-8... done
  zh_CN.UTF-8... done
  zh_SG.UTF-8... done
Generation complete.
正在设置 linux-firmware (1.173.20) ...
update-initramfs: Generating /boot/initrd.img-5.4.0-42-generic
正在设置 libwhoopsie0:amd64 (0.2.62ubuntu0.6) ...
正在设置 liblwres160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 python3-distupgrade (1:18.04.44) ...
正在设置 gpg (2.2.4-1ubuntu1.4) ...
正在设置 thunderbird-locale-zh-cn (1:78.8.1+build1-0ubuntu0.18.04.1) ...
正在设置 libpcap0.8:amd64 (1.8.1-6ubuntu1.18.04.2) ...
正在设置 libpam-systemd:amd64 (237-3ubuntu10.47) ...
正在设置 grub-pc-bin (2.02-2ubuntu8.23) ...
正在设置 initramfs-tools-core (0.130ubuntu3.12) ...
正在设置 libinput10:amd64 (1.10.4-1ubuntu0.18.04.2) ...
正在设置 grub2-common (2.02-2ubuntu8.23) ...
正在设置 initramfs-tools (0.130ubuntu3.12) ...
update-initramfs: deferring update (trigger activated)
正在设置 netplan.io (0.99-0ubuntu3~18.04.4) ...
正在设置 gpg-wks-server (2.2.4-1ubuntu1.4) ...
正在设置 ubuntu-release-upgrader-core (1:18.04.44) ...
正在设置 thunderbird-locale-en (1:78.8.1+build1-0ubuntu0.18.04.1) ...
正在设置 gpg-wks-client (2.2.4-1ubuntu1.4) ...
正在设置 whoopsie (0.2.62ubuntu0.6) ...
正在设置 thunderbird-locale-en-us (1:78.8.1+build1-0ubuntu0.18.04.1) ...
正在设置 libisccfg160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 snapd (2.49.2+18.04) ...
正在安装新版本配置文件 /etc/apparmor.d/usr.lib.snapd.snap-confine.real ...
snapd.failure.service is a disabled or a static unit, not starting it.
snapd.snap-repair.service is a disabled or a static unit, not starting it.
正在设置 nplan (0.99-0ubuntu3~18.04.4) ...
正在设置 ubuntu-minimal (1.417.5) ...
正在设置 ubuntu-release-upgrader-gtk (1:18.04.44) ...
正在设置 grub-pc (2.02-2ubuntu8.23) ...
Sourcing file `/etc/default/grub'
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-5.4.0-74-generic
Found linux image: /boot/vmlinuz-5.4.0-42-generic
Found initrd image: /boot/initrd.img-5.4.0-42-generic
Found memtest86+ image: /boot/memtest86+.elf
Found memtest86+ image: /boot/memtest86+.bin
done
正在设置 libirs160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 libbind9-160:amd64 (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 gnupg (2.2.4-1ubuntu1.4) ...
正在设置 update-notifier (3.192.1.11) ...
正在设置 bind9-host (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 dnsutils (1:9.11.3+dfsg-1ubuntu1.15) ...
正在设置 ubuntu-standard (1.417.5) ...
正在处理用于 systemd (237-3ubuntu10.47) 的触发器 ...
正在处理用于 man-db (2.8.3-2ubuntu0.1) 的触发器 ...
正在处理用于 gnome-menus (3.13.3-11ubuntu1.1) 的触发器 ...
正在处理用于 dbus (1.12.2-1ubuntu1.2) 的触发器 ...
正在处理用于 hicolor-icon-theme (0.17-2) 的触发器 ...
正在处理用于 mime-support (3.60ubuntu1) 的触发器 ...
正在处理用于 ureadahead (0.100.0-21) 的触发器 ...
正在处理用于 desktop-file-utils (0.23-1ubuntu3.18.04.2) 的触发器 ...
正在处理用于 install-info (6.5.0.dfsg.1-2) 的触发器 ...
正在处理用于 plymouth-theme-ubuntu-text (0.9.3-1ubuntu7.18.04.2) 的触发器 ...
update-initramfs: deferring update (trigger activated)
正在处理用于 cracklib-runtime (2.9.2-5build1) 的触发器 ...
正在处理用于 libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.8) 的触发器 ...
正在处理用于 libc-bin (2.27-3ubuntu1.4) 的触发器 ...
正在设置 libmutter-2-0:amd64 (3.28.4+git20200505-0ubuntu18.04.2) ...
正在设置 gir1.2-mutter-2:amd64 (3.28.4+git20200505-0ubuntu18.04.2) ...
正在设置 mutter (3.28.4+git20200505-0ubuntu18.04.2) ...
正在设置 gnome-shell (3.28.4-0ubuntu18.04.7) ...
正在设置 ubuntu-desktop (1.417.5) ...
正在处理用于 initramfs-tools (0.130ubuntu3.12) 的触发器 ...
update-initramfs: Generating /boot/initrd.img-5.4.0-42-generic
正在处理用于 libc-bin (2.27-3ubuntu1.4) 的触发器 ...
jmq@Master:~$ ssh localhost
Welcome to Ubuntu 18.04.5 LTS (GNU/Linux 5.4.0-42-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Canonical Livepatch is available for installation.
   - Reduce system reboots and improve kernel security. Activate at:
     https://ubuntu.com/livepatch

12 updates can be applied immediately.
9 of these updates are standard security updates.
To see these additional updates run: apt list --upgradable

Your Hardware Enablement Stack (HWE) is supported until April 2023.
*** System restart required ***
Last login: Thu Jun 10 03:23:49 2021 from 127.0.0.1
jmq@Master:~$ start-dfs.sh
Starting namenodes on [Master]
Master: Warning: Permanently added the ECDSA host key for IP address '192.168.8.136' to the list of known hosts.
Starting datanodes
Starting secondary namenodes [Master]
jmq@Master:~$ jps
23170 NameNode
23620 SecondaryNameNode
23800 Jps
23355 DataNode
jmq@Master:~$ start-dfs.sh
Starting namenodes on [Master]
Master: namenode is running as process 23170.  Stop it first.
Starting datanodes
Master: datanode is running as process 23355.  Stop it first.
Slave1: datanode is running as process 2962.  Stop it first.
Starting secondary namenodes [Master]
Master: secondarynamenode is running as process 23620.  Stop it first.
jmq@Master:~$ start-yarn.sh
Starting resourcemanager
Starting nodemanagers
jmq@Master:~$ mr-jobhistory-daemon.sh start historyserver
WARNING: Use of this script to start the MR JobHistory daemon is deprecated.
WARNING: Attempting to execute replacement "mapred --daemon start" instead.
jmq@Master:~$ jps
24768 NodeManager
23170 NameNode
23620 SecondaryNameNode
25063 JobHistoryServer
25288 Jps
23355 DataNode
24590 ResourceManager
jmq@Master:~$ sudo mount -t vmhgfs .host:/ /mnt/hgfs
[sudo] j 的密码： 
Error: cannot mount filesystem: No such device
jmq@Master:~$ /# mount -t vmhgfs .host:/ /mnt/hgfs
-bash: /#: 没有那个文件或目录
jmq@Master:~$ sudo vmhgfs-fuse .host:/ /mnt/hgfs
jmq@Master:~$ cd /mnt/hgfs
-bash: cd: /mnt/hgfs: 权限不够
jmq@Master:~$ sudo cd /mnt/hgfs
sudo: cd：找不到命令
jmq@Master:~$ sudo chown 777 /mnt/hgfs
chown: 正在更改'/mnt/hgfs' 的所有者: 没有那个文件或目录
jmq@Master:~$ sudo chown -R /mnt/hgfs
chown: "/mnt/hgfs" 后缺少操作数
Try 'chown --help' for more information.
jmq@Master:~$ sudo umount /mnt/hgfs
jmq@Master:~$ sudo /usr/bin/vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other -o uid=1000 -o gid=1000 -o umask=022
jmq@Master:~$ hadoop fs -ls /
Found 2 items
drwxrwx---   - j supergroup          0 2021-05-28 22:16 /tmp
drwxr-xr-x   - j supergroup          0 2021-05-30 23:26 /user
jmq@Master:~$ hadoop fs -ls /user
Found 3 items
drwxr-xr-x   - j supergroup          0 2021-05-28 23:31 /user/hadoop
drwxr-xr-x   - j supergroup          0 2021-05-30 23:56 /user/j
drwxr-xr-x   - j supergroup          0 2021-05-30 23:26 /user/jmq
jmq@Master:~$ hadoop fs -ls /user/j
Found 2 items
drwxr-xr-x   - j supergroup          0 2021-05-30 23:34 /user/j/input
drwxr-xr-x   - j supergroup          0 2021-05-30 23:56 /user/j/output
jmq@Master:~$ hadoop fs -rm /user/j/input/*
Deleted /user/j/input/a.txt
Deleted /user/j/input/b.txt
Deleted /user/j/input/c.txt
jmq@Master:~$ cd /mnt/hgfs/share2
jmq@Master:/mnt/hgfs/share2$ ls
course.txt  h264Encoder_Decoder-2  hadoop-3.1.3.tar.gz  jdk-8u162-linux-x64.tar.gz  student.txt  watermaking  xuanke.txt  新建文本文档.txt
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put student.txt /user/j/input
2021-06-10 03:44:05,751 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put xuanke.txt /user/j/input
2021-06-10 03:44:14,376 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put course.txt /user/j/input
2021-06-10 03:44:25,243 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ vim ~/.bashrc
jmq@Master:/mnt/hgfs/share2$ hadoop fs -rm /user/j/input/*
Deleted /user/j/input/course.txt
Deleted /user/j/input/student.txt
Deleted /user/j/input/xuanke.txt
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put student.txt /user/j/input

2021-06-10 05:36:37,677 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ 
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put xuanke.txt /user/j/input
2021-06-10 05:37:01,777 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put course.txt /user/j/input
2021-06-10 05:37:10,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ cd /usr/local/hadoop/myapps
-bash: cd: /usr/local/hadoop/myapps: 没有那个文件或目录
jmq@Master:/mnt/hgfs/share2$ cd /usr/local/hadoop/myapp
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar input/xuanke.txt input/student.txt input/course.txt output
JAR does not exist or is not a normal file: /usr/local/hadoop/myapp/input/xuanke.txt
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output

^C2021-06-10 06:01:05,333 WARN fs.FileUtil: Failed to delete file or dir [/tmp/hadoop-unjar4924583060259971155/org/apache]: it still exists.
2021-06-10 06:01:05,409 WARN fs.FileUtil: Failed to delete file or dir [/tmp/hadoop-unjar4924583060259971155/com]: it still exists.
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output

1
2021-06-10 06:03:36,597 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:03:36,755 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:03:38,252 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:03:38,465 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0001
2021-06-10 06:03:38,766 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:03:42,184 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:03:42,379 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:03:42,427 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:03:42,886 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:03:43,137 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:03:43,571 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0001
2021-06-10 06:03:43,571 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:03:43,886 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:03:43,887 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:03:45,165 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0001
2021-06-10 06:03:45,243 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0001/
2021-06-10 06:03:45,244 INFO mapreduce.Job: Running job: job_1623267483546_0001
2021-06-10 06:04:09,229 INFO mapreduce.Job: Job job_1623267483546_0001 running in uber mode : false
2021-06-10 06:04:09,232 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:04:15,341 INFO mapreduce.Job: Task Id : attempt_1623267483546_0001_m_000000_0, Status : FAILED
Error: java.lang.NullPointerException
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:100)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 06:04:20,419 INFO mapreduce.Job: Task Id : attempt_1623267483546_0001_m_000000_1, Status : FAILED
Error: java.lang.NullPointerException
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:100)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 06:04:26,481 INFO mapreduce.Job: Task Id : attempt_1623267483546_0001_m_000000_2, Status : FAILED
Error: java.lang.NullPointerException
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:100)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 06:04:35,584 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:04:35,623 INFO mapreduce.Job: Job job_1623267483546_0001 failed with state FAILED due to: Task failed task_1623267483546_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 06:04:35,857 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=36110
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=18055
		Total vcore-milliseconds taken by all map tasks=18055
		Total megabyte-milliseconds taken by all map tasks=36976640
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
1
2021-06-10 06:10:54,998 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:10:55,135 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:10:55,814 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:10:55,850 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0002
2021-06-10 06:10:56,032 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:10:57,236 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:10:57,296 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:10:57,331 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:10:57,755 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:10:57,923 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:10:58,351 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0002
2021-06-10 06:10:58,351 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:10:58,558 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:10:58,559 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:10:58,643 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0002
2021-06-10 06:10:58,707 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0002/
2021-06-10 06:10:58,708 INFO mapreduce.Job: Running job: job_1623267483546_0002
2021-06-10 06:11:12,026 INFO mapreduce.Job: Job job_1623267483546_0002 running in uber mode : false
2021-06-10 06:11:12,027 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:11:19,130 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:11:24,170 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:11:25,185 INFO mapreduce.Job: Job job_1623267483546_0002 completed successfully
2021-06-10 06:11:25,262 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=436951
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=9258
		Total time spent by all reduces in occupied slots (ms)=6688
		Total time spent by all map tasks (ms)=4629
		Total time spent by all reduce tasks (ms)=3344
		Total vcore-milliseconds taken by all map tasks=4629
		Total vcore-milliseconds taken by all reduce tasks=3344
		Total megabyte-milliseconds taken by all map tasks=9480192
		Total megabyte-milliseconds taken by all reduce tasks=6848512
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=216
		CPU time spent (ms)=2120
		Physical memory (bytes) snapshot=497967104
		Virtual memory (bytes) snapshot=6896242688
		Total committed heap usage (bytes)=387448832
		Peak Map Physical memory (bytes)=301117440
		Peak Map Virtual memory (bytes)=2888978432
		Peak Reduce Physical memory (bytes)=196849664
		Peak Reduce Virtual memory (bytes)=4007264256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  output
Found 2 items
-rw-r--r--   3 j supergroup          0 2021-06-10 06:11 output/_SUCCESS
-rw-r--r--   3 j supergroup          0 2021-06-10 06:11 output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
1
2021-06-10 06:13:36,609 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:13:36,752 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:13:37,796 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:13:37,855 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0003
2021-06-10 06:13:38,073 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:13:39,238 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:13:39,329 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:13:39,384 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:13:39,416 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:13:39,689 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:13:40,131 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0003
2021-06-10 06:13:40,132 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:13:40,428 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:13:40,428 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:13:40,553 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0003
2021-06-10 06:13:40,626 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0003/
2021-06-10 06:13:40,627 INFO mapreduce.Job: Running job: job_1623267483546_0003
2021-06-10 06:13:55,015 INFO mapreduce.Job: Job job_1623267483546_0003 running in uber mode : false
2021-06-10 06:13:55,017 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:14:03,273 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:14:14,459 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:14:14,471 INFO mapreduce.Job: Job job_1623267483546_0003 completed successfully
2021-06-10 06:14:14,626 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=436951
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=12462
		Total time spent by all reduces in occupied slots (ms)=16016
		Total time spent by all map tasks (ms)=6231
		Total time spent by all reduce tasks (ms)=8008
		Total vcore-milliseconds taken by all map tasks=6231
		Total vcore-milliseconds taken by all reduce tasks=8008
		Total megabyte-milliseconds taken by all map tasks=12761088
		Total megabyte-milliseconds taken by all reduce tasks=16400384
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=466
		CPU time spent (ms)=5050
		Physical memory (bytes) snapshot=541220864
		Virtual memory (bytes) snapshot=6890844160
		Total committed heap usage (bytes)=417857536
		Peak Map Physical memory (bytes)=328028160
		Peak Map Virtual memory (bytes)=2886082560
		Peak Reduce Physical memory (bytes)=213192704
		Peak Reduce Virtual memory (bytes)=4004761600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  output
Found 2 items
-rw-r--r--   3 j supergroup          0 2021-06-10 06:14 output/_SUCCESS
-rw-r--r--   3 j supergroup          0 2021-06-10 06:14 output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
1
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:22:39,883 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:22:40,051 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:22:40,880 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:22:40,911 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0004
2021-06-10 06:22:41,074 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:22:42,423 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:22:42,491 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:22:42,535 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:22:42,560 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:22:42,734 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:22:43,161 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0004
2021-06-10 06:22:43,161 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:22:43,349 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:22:43,350 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:22:43,420 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0004
2021-06-10 06:22:43,469 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0004/
2021-06-10 06:22:43,469 INFO mapreduce.Job: Running job: job_1623267483546_0004
2021-06-10 06:22:54,905 INFO mapreduce.Job: Job job_1623267483546_0004 running in uber mode : false
2021-06-10 06:22:54,906 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:23:01,003 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:23:07,054 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:23:09,075 INFO mapreduce.Job: Job job_1623267483546_0004 completed successfully
2021-06-10 06:23:09,187 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=437309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8168
		Total time spent by all reduces in occupied slots (ms)=5740
		Total time spent by all map tasks (ms)=4084
		Total time spent by all reduce tasks (ms)=2870
		Total vcore-milliseconds taken by all map tasks=4084
		Total vcore-milliseconds taken by all reduce tasks=2870
		Total megabyte-milliseconds taken by all map tasks=8364032
		Total megabyte-milliseconds taken by all reduce tasks=5877760
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=146
		CPU time spent (ms)=1670
		Physical memory (bytes) snapshot=509087744
		Virtual memory (bytes) snapshot=6893522944
		Total committed heap usage (bytes)=365953024
		Peak Map Physical memory (bytes)=301940736
		Peak Map Virtual memory (bytes)=2887897088
		Peak Reduce Physical memory (bytes)=207147008
		Peak Reduce Virtual memory (bytes)=4005625856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
1
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:25:31,416 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:25:31,555 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:25:32,268 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:25:32,313 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0005
2021-06-10 06:25:32,459 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:25:33,175 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:25:33,493 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:25:33,947 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:25:34,379 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:25:34,534 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:25:34,556 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0005
2021-06-10 06:25:34,556 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:25:34,811 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:25:34,812 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:25:34,908 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0005
2021-06-10 06:25:34,969 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0005/
2021-06-10 06:25:34,970 INFO mapreduce.Job: Running job: job_1623267483546_0005
2021-06-10 06:25:47,231 INFO mapreduce.Job: Job job_1623267483546_0005 running in uber mode : false
2021-06-10 06:25:47,233 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:25:53,333 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:26:01,403 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:26:02,419 INFO mapreduce.Job: Job job_1623267483546_0005 completed successfully
2021-06-10 06:26:02,508 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=437309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8218
		Total time spent by all reduces in occupied slots (ms)=9092
		Total time spent by all map tasks (ms)=4109
		Total time spent by all reduce tasks (ms)=4546
		Total vcore-milliseconds taken by all map tasks=4109
		Total vcore-milliseconds taken by all reduce tasks=4546
		Total megabyte-milliseconds taken by all map tasks=8415232
		Total megabyte-milliseconds taken by all reduce tasks=9310208
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=215
		CPU time spent (ms)=2170
		Physical memory (bytes) snapshot=549163008
		Virtual memory (bytes) snapshot=6893428736
		Total committed heap usage (bytes)=415236096
		Peak Map Physical memory (bytes)=329330688
		Peak Map Virtual memory (bytes)=2886840320
		Peak Reduce Physical memory (bytes)=219832320
		Peak Reduce Virtual memory (bytes)=4006588416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
1
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:28:22,887 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:28:23,008 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:28:23,734 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:28:23,777 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0006
2021-06-10 06:28:23,973 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:28:24,709 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:28:24,890 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:28:25,412 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:28:25,839 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:28:25,998 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:28:26,422 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0006
2021-06-10 06:28:26,422 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:28:26,644 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:28:26,644 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:28:26,744 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0006
2021-06-10 06:28:26,809 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0006/
2021-06-10 06:28:26,810 INFO mapreduce.Job: Running job: job_1623267483546_0006
2021-06-10 06:28:41,115 INFO mapreduce.Job: Job job_1623267483546_0006 running in uber mode : false
2021-06-10 06:28:41,118 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:28:48,282 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:28:56,383 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:28:56,396 INFO mapreduce.Job: Job job_1623267483546_0006 completed successfully
2021-06-10 06:28:56,527 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=437309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=9314
		Total time spent by all reduces in occupied slots (ms)=9690
		Total time spent by all map tasks (ms)=4657
		Total time spent by all reduce tasks (ms)=4845
		Total vcore-milliseconds taken by all map tasks=4657
		Total vcore-milliseconds taken by all reduce tasks=4845
		Total megabyte-milliseconds taken by all map tasks=9537536
		Total megabyte-milliseconds taken by all reduce tasks=9922560
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=246
		CPU time spent (ms)=3230
		Physical memory (bytes) snapshot=518520832
		Virtual memory (bytes) snapshot=6899187712
		Total committed heap usage (bytes)=390070272
		Peak Map Physical memory (bytes)=301219840
		Peak Map Virtual memory (bytes)=2888916992
		Peak Reduce Physical memory (bytes)=217300992
		Peak Reduce Virtual memory (bytes)=4010270720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  input
Found 3 items
-rw-r--r--   3 j supergroup         73 2021-06-10 05:37 input/course.txt
-rw-r--r--   3 j supergroup        135 2021-06-10 05:36 input/student.txt
-rw-r--r--   3 j supergroup        349 2021-06-10 05:37 input/xuanke.txt
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  hdfs://Master:9000/user/root/input/
ls: `hdfs://Master:9000/user/root/input/': No such file or directory
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  hdfs://Master:9000/user/j/input/
Found 3 items
-rw-r--r--   3 j supergroup         73 2021-06-10 05:37 hdfs://Master:9000/user/j/input/course.txt
-rw-r--r--   3 j supergroup        135 2021-06-10 05:36 hdfs://Master:9000/user/j/input/student.txt
-rw-r--r--   3 j supergroup        349 2021-06-10 05:37 hdfs://Master:9000/user/j/input/xuanke.txt
jmq@Master:/usr/local/hadoop/myapp$ ^C
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  hdfs://Master:9000/user/root/
ls: `hdfs://Master:9000/user/root/': No such file or directory
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -mkdir  hdfs://Master:9000/user/root/
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -mkdir  hdfs://Master:9000/user/root/input
jmq@Master:/usr/local/hadoop/myapp$ cd /mnt/hgfs/share2
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put course.txt /user/root/input
2021-06-10 06:34:13,871 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ hadoop fs -put student.txt /user/root/input
2021-06-10 06:34:20,882 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
^[[Ajmq@Master:/mnt/hgfs/share2$ hadoop fs -put xuanke.txt /user/root/input
2021-06-10 06:34:30,071 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
jmq@Master:/mnt/hgfs/share2$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
JAR does not exist or is not a normal file: /mnt/hgfs/share2/dblj.jar
jmq@Master:/mnt/hgfs/share2$ cd /usr/local/hadoop/myapp
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:38:38,872 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:38:39,224 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:38:41,439 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:38:41,507 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0007
2021-06-10 06:38:42,193 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:38:44,795 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:38:44,949 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:38:45,006 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:38:45,030 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:38:45,578 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:38:45,627 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0007
2021-06-10 06:38:45,628 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:38:46,350 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:38:46,351 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:38:46,548 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0007
2021-06-10 06:38:46,664 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0007/
2021-06-10 06:38:46,666 INFO mapreduce.Job: Running job: job_1623267483546_0007
2021-06-10 06:39:14,409 INFO mapreduce.Job: Job job_1623267483546_0007 running in uber mode : false
2021-06-10 06:39:14,413 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:39:36,491 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:39:49,705 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:39:49,791 INFO mapreduce.Job: Job job_1623267483546_0007 completed successfully
2021-06-10 06:39:50,213 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=437653
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=38880
		Total time spent by all reduces in occupied slots (ms)=20406
		Total time spent by all map tasks (ms)=19440
		Total time spent by all reduce tasks (ms)=10203
		Total vcore-milliseconds taken by all map tasks=19440
		Total vcore-milliseconds taken by all reduce tasks=10203
		Total megabyte-milliseconds taken by all map tasks=39813120
		Total megabyte-milliseconds taken by all reduce tasks=20895744
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=600
		CPU time spent (ms)=8010
		Physical memory (bytes) snapshot=467709952
		Virtual memory (bytes) snapshot=6892630016
		Total committed heap usage (bytes)=394264576
		Peak Map Physical memory (bytes)=293781504
		Peak Map Virtual memory (bytes)=2887028736
		Peak Reduce Physical memory (bytes)=173928448
		Peak Reduce Virtual memory (bytes)=4005601280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
^[[A^[[A^[[A^[[Ajmq@Master:/usr/locahadoop fs -ls  output/
Found 2 items
-rw-r--r--   3 j supergroup          0 2021-06-10 06:39 output/_SUCCESS
-rw-r--r--   3 j supergroup          0 2021-06-10 06:39 output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:45:36,408 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:45:36,585 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:45:38,234 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:45:38,283 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0008
2021-06-10 06:45:38,500 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:45:39,246 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:45:39,333 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:45:39,416 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:45:39,434 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:45:39,752 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:45:39,785 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0008
2021-06-10 06:45:39,786 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:45:40,229 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:45:40,229 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:45:40,402 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0008
2021-06-10 06:45:40,485 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0008/
2021-06-10 06:45:40,486 INFO mapreduce.Job: Running job: job_1623267483546_0008
2021-06-10 06:45:53,840 INFO mapreduce.Job: Job job_1623267483546_0008 running in uber mode : false
2021-06-10 06:45:53,842 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:45:59,952 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:46:08,031 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:46:08,046 INFO mapreduce.Job: Job job_1623267483546_0008 completed successfully
2021-06-10 06:46:08,183 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=60
		FILE: Number of bytes written=437417
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=36
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8314
		Total time spent by all reduces in occupied slots (ms)=9278
		Total time spent by all map tasks (ms)=4157
		Total time spent by all reduce tasks (ms)=4639
		Total vcore-milliseconds taken by all map tasks=4157
		Total vcore-milliseconds taken by all reduce tasks=4639
		Total megabyte-milliseconds taken by all map tasks=8513536
		Total megabyte-milliseconds taken by all reduce tasks=9500672
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=36
		Map output materialized bytes=60
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=60
		Reduce input records=9
		Reduce output records=9
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=213
		CPU time spent (ms)=3010
		Physical memory (bytes) snapshot=511045632
		Virtual memory (bytes) snapshot=6894907392
		Total committed heap usage (bytes)=383778816
		Peak Map Physical memory (bytes)=301350912
		Peak Map Virtual memory (bytes)=2888396800
		Peak Reduce Physical memory (bytes)=209694720
		Peak Reduce Virtual memory (bytes)=4006510592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=36
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  output/
Found 2 items
-rw-r--r--   3 j supergroup          0 2021-06-10 06:46 output/_SUCCESS
-rw-r--r--   3 j supergroup         36 2021-06-10 06:46 output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
2021-06-10 06:46:50,797 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
1	2
1	2
1	2
1	2
1	2
1	2
1	2
1	2
1	2
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:48:06,426 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:48:06,555 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:48:07,347 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:48:07,380 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0009
2021-06-10 06:48:07,591 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:48:08,332 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:48:08,447 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:48:08,493 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:48:08,921 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:48:09,138 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:48:09,172 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0009
2021-06-10 06:48:09,172 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:48:09,486 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:48:09,486 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:48:09,615 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0009
2021-06-10 06:48:09,699 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0009/
2021-06-10 06:48:09,700 INFO mapreduce.Job: Running job: job_1623267483546_0009
2021-06-10 06:48:22,909 INFO mapreduce.Job: Job job_1623267483546_0009 running in uber mode : false
2021-06-10 06:48:22,910 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:48:29,009 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:48:36,082 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:48:38,121 INFO mapreduce.Job: Job job_1623267483546_0009 completed successfully
2021-06-10 06:48:38,301 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=148
		FILE: Number of bytes written=437593
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=124
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8900
		Total time spent by all reduces in occupied slots (ms)=9884
		Total time spent by all map tasks (ms)=4450
		Total time spent by all reduce tasks (ms)=4942
		Total vcore-milliseconds taken by all map tasks=4450
		Total vcore-milliseconds taken by all reduce tasks=4942
		Total megabyte-milliseconds taken by all map tasks=9113600
		Total megabyte-milliseconds taken by all reduce tasks=10121216
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=124
		Map output materialized bytes=148
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=148
		Reduce input records=9
		Reduce output records=9
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=272
		CPU time spent (ms)=3100
		Physical memory (bytes) snapshot=528871424
		Virtual memory (bytes) snapshot=6895202304
		Total committed heap usage (bytes)=416808960
		Peak Map Physical memory (bytes)=329023488
		Peak Map Virtual memory (bytes)=2888663040
		Peak Reduce Physical memory (bytes)=199847936
		Peak Reduce Virtual memory (bytes)=4006539264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=124
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
2021-06-10 06:48:47,476 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
20173822	C309
20184484	B12
20184484	A912
20184484	C309
20188888	A912
20188888	C309
20194832	B12
20194832	A912
20194832	C309
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:51:50,006 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:51:50,193 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:51:51,078 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:51:51,111 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0010
2021-06-10 06:51:51,383 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:51:52,200 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:51:52,279 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:51:52,318 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:51:52,339 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:51:52,610 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:51:52,667 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0010
2021-06-10 06:51:52,667 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:51:53,033 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:51:53,034 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:51:53,173 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0010
2021-06-10 06:51:53,248 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0010/
2021-06-10 06:51:53,250 INFO mapreduce.Job: Running job: job_1623267483546_0010
2021-06-10 06:52:08,518 INFO mapreduce.Job: Job job_1623267483546_0010 running in uber mode : false
2021-06-10 06:52:08,520 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:52:16,669 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:52:23,748 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:52:24,769 INFO mapreduce.Job: Job job_1623267483546_0010 completed successfully
2021-06-10 06:52:24,935 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=148
		FILE: Number of bytes written=437593
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=124
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=11226
		Total time spent by all reduces in occupied slots (ms)=10870
		Total time spent by all map tasks (ms)=5613
		Total time spent by all reduce tasks (ms)=5435
		Total vcore-milliseconds taken by all map tasks=5613
		Total vcore-milliseconds taken by all reduce tasks=5435
		Total megabyte-milliseconds taken by all map tasks=11495424
		Total megabyte-milliseconds taken by all reduce tasks=11130880
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=124
		Map output materialized bytes=148
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=148
		Reduce input records=9
		Reduce output records=9
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=268
		CPU time spent (ms)=3490
		Physical memory (bytes) snapshot=523526144
		Virtual memory (bytes) snapshot=6893400064
		Total committed heap usage (bytes)=388497408
		Peak Map Physical memory (bytes)=302055424
		Peak Map Virtual memory (bytes)=2886561792
		Peak Reduce Physical memory (bytes)=221470720
		Peak Reduce Virtual memory (bytes)=4006838272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=124
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
2021-06-10 06:52:33,366 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
20173822	C309
20184484	B12
20184484	A912
20184484	C309
20188888	A912
20188888	C309
20194832	B12
20194832	A912
20194832	C309
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:55:59,709 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:55:59,815 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:56:00,529 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:56:00,559 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0011
2021-06-10 06:56:00,777 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:56:01,474 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:56:01,536 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:56:01,578 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:56:01,607 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:56:01,872 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:56:01,949 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0011
2021-06-10 06:56:01,952 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:56:02,410 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:56:02,410 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:56:02,531 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0011
2021-06-10 06:56:02,595 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0011/
2021-06-10 06:56:02,596 INFO mapreduce.Job: Running job: job_1623267483546_0011
2021-06-10 06:56:13,770 INFO mapreduce.Job: Job job_1623267483546_0011 running in uber mode : false
2021-06-10 06:56:13,772 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:56:17,837 INFO mapreduce.Job: Task Id : attempt_1623267483546_0011_m_000000_0, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:158)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 06:56:22,914 INFO mapreduce.Job: Task Id : attempt_1623267483546_0011_m_000000_1, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:158)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 06:56:28,971 INFO mapreduce.Job: Task Id : attempt_1623267483546_0011_m_000000_2, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:158)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 06:56:36,040 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:56:37,062 INFO mapreduce.Job: Job job_1623267483546_0011 failed with state FAILED due to: Task failed task_1623267483546_0011_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 06:56:37,183 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=29228
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=14614
		Total vcore-milliseconds taken by all map tasks=14614
		Total megabyte-milliseconds taken by all map tasks=29929472
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 06:58:26,554 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 06:58:26,704 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 06:58:27,527 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 06:58:27,562 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0012
2021-06-10 06:58:27,777 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:58:28,376 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 06:58:28,458 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:58:28,499 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:58:28,519 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 06:58:28,771 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 06:58:28,817 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0012
2021-06-10 06:58:28,817 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 06:58:29,190 INFO conf.Configuration: resource-types.xml not found
2021-06-10 06:58:29,191 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 06:58:29,320 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0012
2021-06-10 06:58:29,406 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0012/
2021-06-10 06:58:29,407 INFO mapreduce.Job: Running job: job_1623267483546_0012
2021-06-10 06:58:43,646 INFO mapreduce.Job: Job job_1623267483546_0012 running in uber mode : false
2021-06-10 06:58:43,648 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 06:58:49,754 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 06:58:56,857 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 06:58:57,879 INFO mapreduce.Job: Job job_1623267483546_0012 completed successfully
2021-06-10 06:58:58,115 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=141
		FILE: Number of bytes written=437579
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=117
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8588
		Total time spent by all reduces in occupied slots (ms)=8918
		Total time spent by all map tasks (ms)=4294
		Total time spent by all reduce tasks (ms)=4459
		Total vcore-milliseconds taken by all map tasks=4294
		Total vcore-milliseconds taken by all reduce tasks=4459
		Total megabyte-milliseconds taken by all map tasks=8794112
		Total megabyte-milliseconds taken by all reduce tasks=9132032
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=117
		Map output materialized bytes=141
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=141
		Reduce input records=9
		Reduce output records=9
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=407
		CPU time spent (ms)=2670
		Physical memory (bytes) snapshot=525676544
		Virtual memory (bytes) snapshot=6892744704
		Total committed heap usage (bytes)=395313152
		Peak Map Physical memory (bytes)=303140864
		Peak Map Virtual memory (bytes)=2885746688
		Peak Reduce Physical memory (bytes)=222535680
		Peak Reduce Virtual memory (bytes)=4006998016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=117
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
2021-06-10 06:59:09,606 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
xuanke.txt	?
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 07:02:29,082 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:02:29,211 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:02:30,024 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 07:02:30,057 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0013
2021-06-10 07:02:30,260 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:02:30,786 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 07:02:30,849 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:02:30,885 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:02:30,900 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 07:02:31,125 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:02:31,200 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0013
2021-06-10 07:02:31,200 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:02:31,591 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:02:31,591 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:02:31,718 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0013
2021-06-10 07:02:31,824 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0013/
2021-06-10 07:02:31,827 INFO mapreduce.Job: Running job: job_1623267483546_0013
2021-06-10 07:02:48,470 INFO mapreduce.Job: Job job_1623267483546_0013 running in uber mode : false
2021-06-10 07:02:48,472 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:02:55,589 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 07:03:02,678 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:03:03,699 INFO mapreduce.Job: Job job_1623267483546_0013 completed successfully
2021-06-10 07:03:03,845 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=177
		FILE: Number of bytes written=437651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=153
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=8300
		Total time spent by all reduces in occupied slots (ms)=10136
		Total time spent by all map tasks (ms)=4150
		Total time spent by all reduce tasks (ms)=5068
		Total vcore-milliseconds taken by all map tasks=4150
		Total vcore-milliseconds taken by all reduce tasks=5068
		Total megabyte-milliseconds taken by all map tasks=8499200
		Total megabyte-milliseconds taken by all reduce tasks=10379264
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=153
		Map output materialized bytes=177
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=177
		Reduce input records=9
		Reduce output records=9
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=230
		CPU time spent (ms)=2860
		Physical memory (bytes) snapshot=538619904
		Virtual memory (bytes) snapshot=6898352128
		Total committed heap usage (bytes)=409468928
		Peak Map Physical memory (bytes)=329658368
		Peak Map Virtual memory (bytes)=2892562432
		Peak Reduce Physical memory (bytes)=208961536
		Peak Reduce Virtual memory (bytes)=4005789696
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=153
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
2021-06-10 07:03:24,810 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
nullxuanke.txt	?
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 07:05:54,603 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:05:54,711 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:05:55,333 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 07:05:55,361 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0014
2021-06-10 07:05:55,598 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:05:56,081 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 07:05:56,136 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:05:56,189 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:05:56,201 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 07:05:56,390 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:05:56,413 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0014
2021-06-10 07:05:56,413 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:05:56,724 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:05:56,725 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:05:56,852 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0014
2021-06-10 07:05:56,908 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0014/
2021-06-10 07:05:56,909 INFO mapreduce.Job: Running job: job_1623267483546_0014
2021-06-10 07:06:08,057 INFO mapreduce.Job: Job job_1623267483546_0014 running in uber mode : false
2021-06-10 07:06:08,058 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:06:14,160 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 07:06:19,224 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:06:20,241 INFO mapreduce.Job: Job job_1623267483546_0014 completed successfully
2021-06-10 07:06:20,360 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=177
		FILE: Number of bytes written=435383
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=153
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7190
		Total time spent by all reduces in occupied slots (ms)=7050
		Total time spent by all map tasks (ms)=3595
		Total time spent by all reduce tasks (ms)=3525
		Total vcore-milliseconds taken by all map tasks=3595
		Total vcore-milliseconds taken by all reduce tasks=3525
		Total megabyte-milliseconds taken by all map tasks=7362560
		Total megabyte-milliseconds taken by all reduce tasks=7219200
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=153
		Map output materialized bytes=177
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=177
		Reduce input records=9
		Reduce output records=9
		Spilled Records=18
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=281
		CPU time spent (ms)=2000
		Physical memory (bytes) snapshot=510353408
		Virtual memory (bytes) snapshot=6895878144
		Total committed heap usage (bytes)=385351680
		Peak Map Physical memory (bytes)=291033088
		Peak Map Virtual memory (bytes)=2889437184
		Peak Reduce Physical memory (bytes)=219320320
		Peak Reduce Virtual memory (bytes)=4006440960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=153
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 3
	at duobiaolianjie.aaa.main(aaa.java:48)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
input/xuanke.txt
input/student.txt
input/course.txt
output
2021-06-10 07:12:03,492 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:12:03,597 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
Exception in thread "main" org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://Master:9000/user/j/output already exists
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:164)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
^C2021-06-10 07:12:58,526 WARN fs.FileUtil: Failed to delete file or dir [/tmp/hadoop-unjar9188396287346763719/org/apache]: it still exists.

jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
#######
input
output
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
	at duobiaolianjie.aaa.main(aaa.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
2021-06-10 07:13:53,176 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:13:53,268 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:13:53,809 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0015
2021-06-10 07:13:53,923 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:13:54,415 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0015
Exception in thread "main" org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://Master:9000/user/j/output
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
2021-06-10 07:15:18,117 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:15:18,215 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:15:18,757 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0016
2021-06-10 07:15:18,860 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:15:19,328 INFO input.FileInputFormat: Total input files to process : 2
2021-06-10 07:15:19,395 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:15:19,421 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:15:19,442 INFO mapreduce.JobSubmitter: number of splits:2
2021-06-10 07:15:19,610 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:15:19,633 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0016
2021-06-10 07:15:19,634 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:15:19,871 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:15:19,872 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:15:19,948 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0016
2021-06-10 07:15:20,003 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0016/
2021-06-10 07:15:20,004 INFO mapreduce.Job: Running job: job_1623267483546_0016
2021-06-10 07:15:29,123 INFO mapreduce.Job: Job job_1623267483546_0016 running in uber mode : false
2021-06-10 07:15:29,125 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:15:34,200 INFO mapreduce.Job: Task Id : attempt_1623267483546_0016_m_000001_0, Status : FAILED
Error: java.io.FileNotFoundException: course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:123)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:15:35,258 INFO mapreduce.Job:  map 50% reduce 0%
2021-06-10 07:15:40,298 INFO mapreduce.Job: Task Id : attempt_1623267483546_0016_m_000001_1, Status : FAILED
Error: java.io.FileNotFoundException: course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:123)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:15:44,329 INFO mapreduce.Job: Task Id : attempt_1623267483546_0016_m_000001_2, Status : FAILED
Error: java.io.FileNotFoundException: course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:123)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:15:50,363 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:15:51,374 INFO mapreduce.Job: Job job_1623267483546_0016 failed with state FAILED due to: Task failed task_1623267483546_0016_m_000001
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 07:15:51,475 INFO mapreduce.Job: Counters: 41
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=217845
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=3
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=5
		Launched reduce tasks=1
		Other local map tasks=3
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=35850
		Total time spent by all reduces in occupied slots (ms)=24218
		Total time spent by all map tasks (ms)=17925
		Total time spent by all reduce tasks (ms)=12109
		Total vcore-milliseconds taken by all map tasks=17925
		Total vcore-milliseconds taken by all reduce tasks=12109
		Total megabyte-milliseconds taken by all map tasks=36710400
		Total megabyte-milliseconds taken by all reduce tasks=24799232
	Map-Reduce Framework
		Map input records=9
		Map output records=9
		Map output bytes=117
		Map output materialized bytes=141
		Input split bytes=107
		Combine input records=0
		Spilled Records=9
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=98
		CPU time spent (ms)=1080
		Physical memory (bytes) snapshot=306941952
		Virtual memory (bytes) snapshot=2887766016
		Total committed heap usage (bytes)=260046848
		Peak Map Physical memory (bytes)=306941952
		Peak Map Virtual memory (bytes)=2887766016
	File Input Format Counters 
		Bytes Read=349
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
cat: `output/part-r-00000': No such file or directory
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -ls  input/
Found 2 items
-rw-r--r--   3 j supergroup         73 2021-06-10 05:37 input/course.txt
-rw-r--r--   3 j supergroup        349 2021-06-10 05:37 input/xuanke.txt
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
#######
2021-06-10 07:24:11,234 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:24:11,383 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:24:12,315 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0017
2021-06-10 07:24:12,473 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:24:13,111 INFO input.FileInputFormat: Total input files to process : 3
2021-06-10 07:24:13,167 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:24:13,199 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:24:13,215 INFO mapreduce.JobSubmitter: number of splits:3
2021-06-10 07:24:13,467 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:24:13,806 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0017
2021-06-10 07:24:13,806 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:24:14,061 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:24:14,061 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:24:14,166 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0017
2021-06-10 07:24:14,233 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0017/
2021-06-10 07:24:14,234 INFO mapreduce.Job: Running job: job_1623267483546_0017
2021-06-10 07:24:27,430 INFO mapreduce.Job: Job job_1623267483546_0017 running in uber mode : false
2021-06-10 07:24:27,432 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:24:57,080 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000002_0, Status : FAILED
Error: java.io.FileNotFoundException: course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:122)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:24:57,152 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000000_0, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:163)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:24:57,158 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000001_0, Status : FAILED
Error: java.io.FileNotFoundException: student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:113)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:10,430 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000002_1, Status : FAILED
Error: java.io.FileNotFoundException: course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:122)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:10,435 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000000_1, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:163)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:11,449 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000001_1, Status : FAILED
Error: java.io.FileNotFoundException: student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:113)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:19,601 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000002_2, Status : FAILED
Error: java.io.FileNotFoundException: course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:122)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:19,612 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000000_2, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:163)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:20,640 INFO mapreduce.Job: Task Id : attempt_1623267483546_0017_m_000001_2, Status : FAILED
Error: java.io.FileNotFoundException: student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:113)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:25:33,963 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:25:34,979 INFO mapreduce.Job: Job job_1623267483546_0017 failed with state FAILED due to: Task failed task_1623267483546_0017_m_000002
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 07:25:35,075 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=10
		Killed map tasks=2
		Killed reduce tasks=1
		Launched map tasks=12
		Other local map tasks=9
		Data-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=347988
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=173994
		Total vcore-milliseconds taken by all map tasks=173994
		Total megabyte-milliseconds taken by all map tasks=356339712
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
#######
2021-06-10 07:29:44,517 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:29:44,659 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:29:45,453 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0018
2021-06-10 07:29:45,600 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:29:46,312 INFO input.FileInputFormat: Total input files to process : 3
2021-06-10 07:29:46,371 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:29:46,813 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:29:46,832 INFO mapreduce.JobSubmitter: number of splits:3
2021-06-10 07:29:47,005 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:29:47,043 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0018
2021-06-10 07:29:47,043 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:29:47,354 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:29:47,355 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:29:47,483 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0018
2021-06-10 07:29:47,556 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0018/
2021-06-10 07:29:47,557 INFO mapreduce.Job: Running job: job_1623267483546_0018
2021-06-10 07:29:58,724 INFO mapreduce.Job: Job job_1623267483546_0018 running in uber mode : false
2021-06-10 07:29:58,725 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:30:06,912 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000000_0, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:164)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:06,943 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000001_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:114)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:06,946 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000002_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:123)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:15,026 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000001_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:114)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:15,028 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000000_1, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:164)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:16,038 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000002_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:123)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:21,090 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000001_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:114)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:21,093 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000000_2, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:164)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:22,104 INFO mapreduce.Job: Task Id : attempt_1623267483546_0018_m_000002_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:123)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:30:28,159 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:30:29,176 INFO mapreduce.Job: Job job_1623267483546_0018 failed with state FAILED due to: Task failed task_1623267483546_0018_m_000001
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 07:30:29,274 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=10
		Killed map tasks=2
		Killed reduce tasks=1
		Launched map tasks=12
		Other local map tasks=9
		Data-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=119876
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=59938
		Total vcore-milliseconds taken by all map tasks=59938
		Total megabyte-milliseconds taken by all map tasks=122753024
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
jmq@Master:/usr/local/hadoop/myapp$ ^C
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
#######
2021-06-10 07:37:56,961 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:37:57,101 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:37:58,016 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0019
2021-06-10 07:37:58,177 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:37:59,024 INFO input.FileInputFormat: Total input files to process : 3
2021-06-10 07:37:59,076 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:37:59,109 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:37:59,122 INFO mapreduce.JobSubmitter: number of splits:3
2021-06-10 07:37:59,318 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:37:59,351 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0019
2021-06-10 07:37:59,352 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:37:59,667 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:37:59,667 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:37:59,783 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0019
2021-06-10 07:37:59,858 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0019/
2021-06-10 07:37:59,860 INFO mapreduce.Job: Running job: job_1623267483546_0019
2021-06-10 07:38:12,103 INFO mapreduce.Job: Job job_1623267483546_0019 running in uber mode : false
2021-06-10 07:38:12,104 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:38:22,766 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000000_0, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:168)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:22,810 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000001_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:118)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:22,814 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000002_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:127)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:32,965 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000000_1, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:168)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:32,968 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000001_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:118)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:33,984 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000002_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:127)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:41,103 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000000_2, Status : FAILED
Error: java.lang.NullPointerException
	at org.apache.hadoop.io.Text.encode(Text.java:451)
	at org.apache.hadoop.io.Text.set(Text.java:198)
	at org.apache.hadoop.io.Text.<init>(Text.java:88)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:168)
	at duobiaolianjie.aaa$TokenizerMapper.map(aaa.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:41,107 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000001_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:118)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:42,129 INFO mapreduce.Job: Task Id : attempt_1623267483546_0019_m_000002_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:127)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:38:50,264 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:38:51,280 INFO mapreduce.Job: Job job_1623267483546_0019 failed with state FAILED due to: Task failed task_1623267483546_0019_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 07:38:51,430 INFO mapreduce.Job: Counters: 14
	Job Counters 
		Failed map tasks=10
		Killed map tasks=2
		Killed reduce tasks=1
		Launched map tasks=12
		Other local map tasks=9
		Data-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=177194
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=88597
		Total vcore-milliseconds taken by all map tasks=88597
		Total megabyte-milliseconds taken by all map tasks=181446656
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
#######
2021-06-10 07:42:53,691 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:42:53,915 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:42:54,503 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0020
2021-06-10 07:42:54,608 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:42:55,064 INFO input.FileInputFormat: Total input files to process : 3
2021-06-10 07:42:55,103 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:42:55,127 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:42:55,140 INFO mapreduce.JobSubmitter: number of splits:3
2021-06-10 07:42:55,285 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:42:55,304 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0020
2021-06-10 07:42:55,305 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:42:55,512 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:42:55,513 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:42:55,593 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0020
2021-06-10 07:42:55,642 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0020/
2021-06-10 07:42:55,643 INFO mapreduce.Job: Running job: job_1623267483546_0020
2021-06-10 07:43:04,747 INFO mapreduce.Job: Job job_1623267483546_0020 running in uber mode : false
2021-06-10 07:43:04,748 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:43:11,870 INFO mapreduce.Job: Task Id : attempt_1623267483546_0020_m_000002_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:126)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:43:11,894 INFO mapreduce.Job: Task Id : attempt_1623267483546_0020_m_000001_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:117)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:43:12,900 INFO mapreduce.Job:  map 33% reduce 0%
2021-06-10 07:43:18,957 INFO mapreduce.Job: Task Id : attempt_1623267483546_0020_m_000001_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:117)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 07:43:18,958 INFO mapreduce.Job: Task Id : attempt_1623267483546_0020_m_000002_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/course.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:126)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input output
#######
2021-06-10 07:46:52,851 INFO duobiaolianjie.aaa: No of Reducers: 1
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 2
	at duobiaolianjie.aaa.main(aaa.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 07:47:06,758 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:47:06,881 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:47:07,536 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0021
2021-06-10 07:47:07,655 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:47:08,112 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0021
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/student.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 07:47:56,800 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:47:56,905 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:47:57,484 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0022
2021-06-10 07:47:57,607 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:47:58,165 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0022
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/student.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 07:56:37,230 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 07:56:37,373 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 07:56:38,176 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 07:56:38,213 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0023
2021-06-10 07:56:38,467 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:56:39,014 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 07:56:39,079 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:56:39,109 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:56:39,124 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 07:56:39,297 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 07:56:39,321 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0023
2021-06-10 07:56:39,321 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 07:56:39,594 INFO conf.Configuration: resource-types.xml not found
2021-06-10 07:56:39,595 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 07:56:39,699 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0023
2021-06-10 07:56:39,756 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0023/
2021-06-10 07:56:39,757 INFO mapreduce.Job: Running job: job_1623267483546_0023
2021-06-10 07:56:49,937 INFO mapreduce.Job: Job job_1623267483546_0023 running in uber mode : false
2021-06-10 07:56:49,939 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 07:56:55,006 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 07:57:01,051 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 07:57:02,067 INFO mapreduce.Job: Job job_1623267483546_0023 completed successfully
2021-06-10 07:57:02,236 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=6
		FILE: Number of bytes written=437309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=456
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5770
		Total time spent by all reduces in occupied slots (ms)=6320
		Total time spent by all map tasks (ms)=2885
		Total time spent by all reduce tasks (ms)=3160
		Total vcore-milliseconds taken by all map tasks=2885
		Total vcore-milliseconds taken by all reduce tasks=3160
		Total megabyte-milliseconds taken by all map tasks=5908480
		Total megabyte-milliseconds taken by all reduce tasks=6471680
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=157
		CPU time spent (ms)=1730
		Physical memory (bytes) snapshot=534339584
		Virtual memory (bytes) snapshot=6896246784
		Total committed heap usage (bytes)=390070272
		Peak Map Physical memory (bytes)=329043968
		Peak Map Virtual memory (bytes)=2888187904
		Peak Reduce Physical memory (bytes)=205295616
		Peak Reduce Virtual memory (bytes)=4008058880
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=0
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:06:19,747 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:06:19,831 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:06:20,500 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:06:20,515 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0024
2021-06-10 08:06:20,620 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:06:20,950 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0024
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/couurse.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:111)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 08:08:12,952 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:08:13,179 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:08:14,404 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:08:14,446 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0025
2021-06-10 08:08:14,704 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:08:15,547 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:08:15,668 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:08:15,735 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:08:15,753 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:08:15,983 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:08:16,422 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0025
2021-06-10 08:08:16,422 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:08:16,697 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:08:16,697 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:08:16,803 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0025
2021-06-10 08:08:16,864 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0025/
2021-06-10 08:08:16,865 INFO mapreduce.Job: Running job: job_1623267483546_0025
2021-06-10 08:08:29,078 INFO mapreduce.Job: Job job_1623267483546_0025 running in uber mode : false
2021-06-10 08:08:29,080 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:08:34,170 INFO mapreduce.Job: Task Id : attempt_1623267483546_0025_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:08:39,241 INFO mapreduce.Job: Task Id : attempt_1623267483546_0025_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C2021-06-10 08:08:43,271 INFO mapreduce.Job: Task Id : attempt_1623267483546_0025_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

jmq@Master:/usr/local/hadoop/myapp$ ^C
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt  output
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 3
	at duobiaolianjie.aaa.main(aaa.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:11:40,403 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:11:40,540 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:11:40,996 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:11:41,014 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0026
2021-06-10 08:11:41,113 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:11:41,527 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:11:41,584 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:11:41,606 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:11:42,015 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:11:42,118 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:11:42,137 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0026
2021-06-10 08:11:42,137 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:11:42,289 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:11:42,290 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:11:42,347 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0026
2021-06-10 08:11:42,382 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0026/
2021-06-10 08:11:42,383 INFO mapreduce.Job: Running job: job_1623267483546_0026
2021-06-10 08:11:50,483 INFO mapreduce.Job: Job job_1623267483546_0026 running in uber mode : false
2021-06-10 08:11:50,484 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:11:53,530 INFO mapreduce.Job: Task Id : attempt_1623267483546_0026_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:11:58,593 INFO mapreduce.Job: Task Id : attempt_1623267483546_0026_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:12:01,613 INFO mapreduce.Job: Task Id : attempt_1623267483546_0026_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:13:33,095 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:13:33,261 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:13:34,283 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:13:34,320 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0027
2021-06-10 08:13:34,554 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:13:35,386 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:13:35,485 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:13:35,575 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:13:35,672 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:13:36,510 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:13:36,541 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0027
2021-06-10 08:13:36,541 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:13:36,894 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:13:36,894 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:13:37,027 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0027
2021-06-10 08:13:37,126 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0027/
2021-06-10 08:13:37,127 INFO mapreduce.Job: Running job: job_1623267483546_0027
2021-06-10 08:13:50,413 INFO mapreduce.Job: Job job_1623267483546_0027 running in uber mode : false
2021-06-10 08:13:50,419 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:13:56,526 INFO mapreduce.Job: Task Id : attempt_1623267483546_0027_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:14:02,603 INFO mapreduce.Job: Task Id : attempt_1623267483546_0027_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:15:48,004 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:15:48,103 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:15:48,658 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:15:48,681 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0028
2021-06-10 08:15:48,801 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:15:49,204 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:15:49,325 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:15:49,406 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:15:49,447 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:15:49,588 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:15:49,751 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0028
2021-06-10 08:15:49,752 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:15:49,975 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:15:49,975 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:15:50,049 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0028
2021-06-10 08:15:50,130 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0028/
2021-06-10 08:15:50,131 INFO mapreduce.Job: Running job: job_1623267483546_0028
2021-06-10 08:15:59,243 INFO mapreduce.Job: Job job_1623267483546_0028 running in uber mode : false
2021-06-10 08:15:59,244 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:16:02,287 INFO mapreduce.Job: Task Id : attempt_1623267483546_0028_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/ /Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:16:06,339 INFO mapreduce.Job: Task Id : attempt_1623267483546_0028_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/ /Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:16:10,368 INFO mapreduce.Job: Task Id : attempt_1623267483546_0028_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/ /Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C
2021-06-10 08:16:16,407 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 08:16:16,420 INFO mapreduce.Job: Job job_1623267483546_0028 failed with state FAILED due to: Task failed task_1623267483546_0028_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 08:16:16,543 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=17176
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=8588
		Total vcore-milliseconds taken by all map tasks=8588
		Total megabyte-milliseconds taken by all map tasks=17588224
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:17:09,429 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:17:09,559 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:17:10,387 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:17:10,412 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0029
2021-06-10 08:17:10,602 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:17:11,223 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:17:11,287 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:17:11,315 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:17:11,331 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:17:11,528 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:17:11,557 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0029
2021-06-10 08:17:11,558 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:17:11,906 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:17:11,907 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:17:12,022 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0029
2021-06-10 08:17:12,086 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0029/
2021-06-10 08:17:12,087 INFO mapreduce.Job: Running job: job_1623267483546_0029
2021-06-10 08:17:28,471 INFO mapreduce.Job: Job job_1623267483546_0029 running in uber mode : false
2021-06-10 08:17:28,473 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:17:33,564 INFO mapreduce.Job: Task Id : attempt_1623267483546_0029_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:17:37,620 INFO mapreduce.Job: Task Id : attempt_1623267483546_0029_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:17:43,683 INFO mapreduce.Job: Task Id : attempt_1623267483546_0029_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:19:22,720 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:19:22,870 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:19:23,729 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:19:23,765 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0030
2021-06-10 08:19:23,967 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:19:24,517 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:19:24,581 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:19:25,012 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:19:25,426 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:19:25,549 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:19:25,569 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0030
2021-06-10 08:19:25,569 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:19:25,781 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:19:25,781 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:19:25,865 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0030
2021-06-10 08:19:25,918 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0030/
2021-06-10 08:19:25,920 INFO mapreduce.Job: Running job: job_1623267483546_0030
2021-06-10 08:19:37,067 INFO mapreduce.Job: Job job_1623267483546_0030 running in uber mode : false
2021-06-10 08:19:37,068 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:19:41,121 INFO mapreduce.Job: Task Id : attempt_1623267483546_0030_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:19:45,162 INFO mapreduce.Job: Task Id : attempt_1623267483546_0030_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:19:49,191 INFO mapreduce.Job: Task Id : attempt_1623267483546_0030_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:110)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:19:55,230 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 08:19:56,242 INFO mapreduce.Job: Job job_1623267483546_0030 failed with state FAILED due to: Task failed task_1623267483546_0030_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 08:19:56,321 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=21176
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=10588
		Total vcore-milliseconds taken by all map tasks=10588
		Total megabyte-milliseconds taken by all map tasks=21684224
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:49:29,494 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:49:29,591 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:49:30,077 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:49:30,097 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0031
2021-06-10 08:49:30,225 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:49:30,594 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:49:30,654 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:49:31,082 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:49:31,493 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:49:31,655 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:49:31,685 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0031
2021-06-10 08:49:31,685 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:49:31,882 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:49:31,882 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:49:31,961 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0031
2021-06-10 08:49:32,008 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0031/
2021-06-10 08:49:32,009 INFO mapreduce.Job: Running job: job_1623267483546_0031
2021-06-10 08:49:40,106 INFO mapreduce.Job: Job job_1623267483546_0031 running in uber mode : false
2021-06-10 08:49:40,108 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:49:43,152 INFO mapreduce.Job: Task Id : attempt_1623267483546_0031_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: /user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:49:47,209 INFO mapreduce.Job: Task Id : attempt_1623267483546_0031_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: /user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:49:51,239 INFO mapreduce.Job: Task Id : attempt_1623267483546_0031_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: /user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C
jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:52:07,840 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:52:07,910 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:52:08,391 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:52:08,407 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0032
2021-06-10 08:52:08,517 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:52:08,852 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:52:08,898 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:52:08,940 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:52:08,945 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:52:09,055 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:52:09,073 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0032
2021-06-10 08:52:09,073 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:52:09,231 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:52:09,231 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:52:09,322 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0032
2021-06-10 08:52:09,354 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0032/
2021-06-10 08:52:09,354 INFO mapreduce.Job: Running job: job_1623267483546_0032
2021-06-10 08:52:17,452 INFO mapreduce.Job: Job job_1623267483546_0032 running in uber mode : false
2021-06-10 08:52:17,453 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:52:20,496 INFO mapreduce.Job: Task Id : attempt_1623267483546_0032_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:52:24,552 INFO mapreduce.Job: Task Id : attempt_1623267483546_0032_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

^C2021-06-10 08:52:27,570 INFO mapreduce.Job: Task Id : attempt_1623267483546_0032_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)


jmq@Master:/usr/local/hadoop/myapp$ 
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 08:54:55,074 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 08:54:55,206 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 08:54:55,666 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 08:54:55,687 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0033
2021-06-10 08:54:55,808 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:54:56,237 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 08:54:56,281 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:54:56,299 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:54:56,311 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 08:54:56,436 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 08:54:56,463 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0033
2021-06-10 08:54:56,463 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 08:54:56,660 INFO conf.Configuration: resource-types.xml not found
2021-06-10 08:54:56,660 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 08:54:56,726 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0033
2021-06-10 08:54:56,769 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0033/
2021-06-10 08:54:56,769 INFO mapreduce.Job: Running job: job_1623267483546_0033
2021-06-10 08:55:04,902 INFO mapreduce.Job: Job job_1623267483546_0033 running in uber mode : false
2021-06-10 08:55:04,903 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 08:55:10,165 INFO mapreduce.Job: Task Id : attempt_1623267483546_0033_m_000000_0, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:55:13,223 INFO mapreduce.Job: Task Id : attempt_1623267483546_0033_m_000000_1, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:55:17,250 INFO mapreduce.Job: Task Id : attempt_1623267483546_0033_m_000000_2, Status : FAILED
Error: java.io.FileNotFoundException: hdfs:/Master:9000/user/j/input/student.txt (没有那个文件或目录)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileReader.<init>(FileReader.java:72)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:111)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 08:55:42,285 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 08:55:44,416 INFO mapreduce.Job: Job job_1623267483546_0033 failed with state FAILED due to: Task failed task_1623267483546_0033_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 08:55:45,177 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=58604
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=29302
		Total vcore-milliseconds taken by all map tasks=29302
		Total megabyte-milliseconds taken by all map tasks=60010496
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 09:08:49,348 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:08:49,573 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:08:50,082 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:08:50,107 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0034
2021-06-10 09:08:50,264 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:08:50,625 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0034
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input#student.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 09:11:10,271 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:11:10,342 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:11:10,759 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:11:10,777 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0035
2021-06-10 09:11:10,887 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:11:11,153 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0035
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/student.txt#student
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:90)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 09:12:35,517 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:12:35,584 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:12:36,031 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:12:36,058 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0036
2021-06-10 09:12:36,181 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:12:36,538 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0036
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/student.txt#student.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:90)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 09:14:12,608 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:14:12,679 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:14:13,087 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:14:13,107 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0037
2021-06-10 09:14:13,220 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:14:13,550 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0037
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/student.txt#student.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:90)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 09:25:01,706 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:25:01,813 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:25:02,276 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:25:02,292 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0038
2021-06-10 09:25:02,421 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:25:02,741 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0038
Exception in thread "main" java.io.FileNotFoundException: File does not exist: hdfs://Master:9000/user/j/input/student.txt#student.txt
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1581)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1574)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1589)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:236)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:105)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:69)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:222)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at duobiaolianjie.aaa.main(aaa.java:91)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
2021-06-10 09:28:21,277 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:28:21,369 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:28:21,929 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:28:21,953 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0039
2021-06-10 09:28:22,098 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:28:22,589 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 09:28:22,711 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:28:22,748 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:28:22,812 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 09:28:23,043 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:28:23,612 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0039
2021-06-10 09:28:23,612 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 09:28:23,757 INFO conf.Configuration: resource-types.xml not found
2021-06-10 09:28:23,757 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 09:28:23,821 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0039
2021-06-10 09:28:23,861 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0039/
2021-06-10 09:28:23,862 INFO mapreduce.Job: Running job: job_1623267483546_0039
2021-06-10 09:28:31,959 INFO mapreduce.Job: Job job_1623267483546_0039 running in uber mode : false
2021-06-10 09:28:31,961 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 09:28:35,002 INFO mapreduce.Job: Task Id : attempt_1623267483546_0039_m_000000_0, Status : FAILED
Error: java.lang.IllegalArgumentException: URI scheme is not "file"
	at java.io.File.<init>(File.java:421)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 09:28:40,060 INFO mapreduce.Job: Task Id : attempt_1623267483546_0039_m_000000_1, Status : FAILED
Error: java.lang.IllegalArgumentException: URI scheme is not "file"
	at java.io.File.<init>(File.java:421)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 09:28:43,085 INFO mapreduce.Job: Task Id : attempt_1623267483546_0039_m_000000_2, Status : FAILED
Error: java.lang.IllegalArgumentException: URI scheme is not "file"
	at java.io.File.<init>(File.java:421)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 09:28:49,129 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 09:28:49,139 INFO mapreduce.Job: Job job_1623267483546_0039 failed with state FAILED due to: Task failed task_1623267483546_0039_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 09:28:49,246 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=18628
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=9314
		Total vcore-milliseconds taken by all map tasks=9314
		Total megabyte-milliseconds taken by all map tasks=19075072
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 09:32:47,970 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:32:48,063 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:32:48,538 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:32:48,554 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0040
2021-06-10 09:32:48,669 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:32:49,104 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 09:32:49,371 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:32:49,470 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:32:49,477 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 09:32:49,584 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:32:49,599 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0040
2021-06-10 09:32:49,599 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 09:32:49,768 INFO conf.Configuration: resource-types.xml not found
2021-06-10 09:32:49,768 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 09:32:49,832 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0040
2021-06-10 09:32:49,873 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0040/
2021-06-10 09:32:49,874 INFO mapreduce.Job: Running job: job_1623267483546_0040
2021-06-10 09:32:57,975 INFO mapreduce.Job: Job job_1623267483546_0040 running in uber mode : false
2021-06-10 09:32:57,977 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 09:33:01,024 INFO mapreduce.Job: Task Id : attempt_1623267483546_0040_m_000000_0, Status : FAILED
Error: java.lang.IllegalArgumentException: URI scheme is not "file"
	at java.io.File.<init>(File.java:421)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 09:33:05,080 INFO mapreduce.Job: Task Id : attempt_1623267483546_0040_m_000000_1, Status : FAILED
Error: java.lang.IllegalArgumentException: URI scheme is not "file"
	at java.io.File.<init>(File.java:421)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 09:33:10,122 INFO mapreduce.Job: Task Id : attempt_1623267483546_0040_m_000000_2, Status : FAILED
Error: java.lang.IllegalArgumentException: URI scheme is not "file"
	at java.io.File.<init>(File.java:421)
	at duobiaolianjie.aaa$TokenizerMapper.setup(aaa.java:112)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)

2021-06-10 09:33:17,209 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 09:33:18,221 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 09:33:18,363 INFO mapreduce.Job: Job job_1623267483546_0040 failed with state FAILED due to: Task failed task_1623267483546_0040_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2021-06-10 09:33:19,226 INFO mapreduce.Job: Counters: 10
	Job Counters 
		Failed map tasks=4
		Killed reduce tasks=1
		Launched map tasks=4
		Other local map tasks=3
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=25222
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=12611
		Total vcore-milliseconds taken by all map tasks=12611
		Total megabyte-milliseconds taken by all map tasks=25827328
jmq@Master:/usr/local/hadoop/myapp$ hadoop jar dblj.jar input/xuanke.txt input/student.txt input/course.txt output
#######
2021-06-10 09:46:08,616 INFO duobiaolianjie.aaa: No of Reducers: 1
2021-06-10 09:46:08,708 INFO client.RMProxy: Connecting to ResourceManager at Master/192.168.8.136:8032
2021-06-10 09:46:09,376 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-06-10 09:46:09,392 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/j/.staging/job_1623267483546_0041
2021-06-10 09:46:09,504 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:46:09,821 INFO input.FileInputFormat: Total input files to process : 1
2021-06-10 09:46:09,926 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:46:10,007 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:46:10,029 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-10 09:46:10,593 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-06-10 09:46:10,627 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1623267483546_0041
2021-06-10 09:46:10,627 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-10 09:46:10,797 INFO conf.Configuration: resource-types.xml not found
2021-06-10 09:46:10,798 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-06-10 09:46:10,863 INFO impl.YarnClientImpl: Submitted application application_1623267483546_0041
2021-06-10 09:46:10,898 INFO mapreduce.Job: The url to track the job: http://Master:8088/proxy/application_1623267483546_0041/
2021-06-10 09:46:10,899 INFO mapreduce.Job: Running job: job_1623267483546_0041
2021-06-10 09:46:18,993 INFO mapreduce.Job: Job job_1623267483546_0041 running in uber mode : false
2021-06-10 09:46:18,994 INFO mapreduce.Job:  map 0% reduce 0%
2021-06-10 09:46:23,037 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-10 09:46:28,070 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-10 09:46:29,085 INFO mapreduce.Job: Job job_1623267483546_0041 completed successfully
2021-06-10 09:46:29,191 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=454
		FILE: Number of bytes written=438309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=664
		HDFS: Number of bytes written=434
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=4124
		Total time spent by all reduces in occupied slots (ms)=4480
		Total time spent by all map tasks (ms)=2062
		Total time spent by all reduce tasks (ms)=2240
		Total vcore-milliseconds taken by all map tasks=2062
		Total vcore-milliseconds taken by all reduce tasks=2240
		Total megabyte-milliseconds taken by all map tasks=4222976
		Total megabyte-milliseconds taken by all reduce tasks=4587520
	Map-Reduce Framework
		Map input records=9
		Map output records=7
		Map output bytes=434
		Map output materialized bytes=454
		Input split bytes=107
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=454
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=99
		CPU time spent (ms)=1280
		Physical memory (bytes) snapshot=534081536
		Virtual memory (bytes) snapshot=6895714304
		Total committed heap usage (bytes)=412090368
		Peak Map Physical memory (bytes)=327933952
		Peak Map Virtual memory (bytes)=2888876032
		Peak Reduce Physical memory (bytes)=206147584
		Peak Reduce Virtual memory (bytes)=4006838272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=349
	File Output Format Counters 
		Bytes Written=434
jmq@Master:/usr/local/hadoop/myapp$ hadoop fs -cat  output/part-r-00000
2021-06-10 09:46:37,980 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
20173822 奶茶	计算机体系结构 38 9月39日 一号楼A403
20184484 胥卜凡	软件工程 88 9月31日 一号楼B320
20184484 胥卜凡	计算机体系结构 38 9月30日 一号楼A405
20188888 贝拉	软件工程 88 9月15日 一号楼A410
20188888 贝拉	计算机体系结构 38 9月30日 一号楼A405
20194832 马云	软件工程 88 9月30日 一号楼A402
20194832 马云	计算机体系结构 38 9月30日 一号楼A402

